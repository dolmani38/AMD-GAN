{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "Adaptive Multi-Discriminator GAN (AMD-GAN).ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a685ada720b644b280841f0590376e52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ae1abdf3fffe46e8ae92b9229695e41a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_bd14da4840cc4dc39428abd0761dd1d4",
              "IPY_MODEL_641368523a33461a9d04c916c7d5136a"
            ]
          }
        },
        "ae1abdf3fffe46e8ae92b9229695e41a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bd14da4840cc4dc39428abd0761dd1d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_90755ae77e87447999b2d90ea3adcafe",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 108857766,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 108857766,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7ccad5a8f8bc49f5b116ad82467e89b2"
          }
        },
        "641368523a33461a9d04c916c7d5136a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d81e495c3900474b86cffbdac341912d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 104M/104M [00:01&lt;00:00, 72.4MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0335acc1438948589dee555dfaf66820"
          }
        },
        "90755ae77e87447999b2d90ea3adcafe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7ccad5a8f8bc49f5b116ad82467e89b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d81e495c3900474b86cffbdac341912d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0335acc1438948589dee555dfaf66820": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dolmani38/AMD-GAN/blob/main/Adaptive%20Multi-Discriminator%20GAN%20(AMD-GAN)_0529.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkQCxNatSIOk"
      },
      "source": [
        "# Multi-Discriminator GAN\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZjIW9VwyjDf"
      },
      "source": [
        "ABSTRACT\n",
        "\n",
        "----\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c20I_OEErmP9"
      },
      "source": [
        "# 3. Related works\n",
        "\n",
        "두개 이상의 discriminator를 사용하는 GAN 연구에 대하여 알아본다.\n",
        "\n",
        "어떤 목적으로 복수의 discriminator를 사용하고 그 효과는 무엇인지 알아본다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uFOIbzcFagq"
      },
      "source": [
        "## 1) N개의 discriminator를 활용한 연구 \n",
        "\n",
        "Generative adversarial networks (Goodfellow et al. (2014))\n",
        "\n",
        "Generator를 multi로 한 연구들...\n",
        "\n",
        "(1) Q. Hoang, T. Dinh Nguyen, T. Le, and D. Phung, “Multi-Generator Generative Adversarial Nets,” ArXiv e-prints, Aug. 2017.\n",
        "\n",
        "(2) Multi-Agent Diverse Generative Adversarial Networks\n",
        "\n",
        "Federated learning의 한 지류가 될수도 있을 것...\n",
        "\n",
        "(1) H. B. McMahan, E. Moore, D. Ramage, and B. A. y Arcas, “Federated learning of deep networks using model averaging,” CoRR, vol. abs/1602.05629, 2016."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fa-0-i84rqoX"
      },
      "source": [
        "## 2) Automatic Image Colorization based on Multi-Discriminators Generative Adversarial Networks [품질향상]\n",
        "\n",
        "GAN은 흑백의 이미지를 입력하여 Color화 된 이미지를 생성해 낼 수 있다.\n",
        "본 논문은 두개의 discriminator를 이용하여 더 produces\n",
        "more realistic quality results.\n",
        "\n",
        "Different from conventional GAN network architecture,\n",
        "Park et al. [13] (S.-J. Park, H. Son, S. Cho, K.-S. Hong, and S. Lee, “Srfeat: Single image super-resolution with feature discrimination,” in Proceedings of the European Conference on Computer Vision, 2018, pp. 439–455.) introduce architecture based on combination of one generator associated with two discriminators. For colorization task, we propose an extended model, illustrated in Fig.1, which uses two discriminators: <font color='red'><b>an image discriminator Di and a feature discriminator Df</b> </font>. The first one discriminates real images (RGB) from colorized images by inspecting their pixel values, while the second discriminates real images from colorized ones by inspecting their feature maps, noted respectively\n",
        "VGG(y) and VGG(G(x)) .\n",
        "\n",
        "본 논문의 Proposed Loss functions 중 GAN에 대한 Loss은 다음과 같다.\n",
        "\n",
        "$$ L_{M-dis}(G,D_i,D_f) = \\lambda_iL_{GAN}(G,D_i) + \\lambda_fL_{GAN}(G,D_f)  $$\n",
        "where lambda_i and lambda_f denote a defined weighting factors\n",
        "\n",
        "실험에 있어서도 lambda_i and lambda_f 의 값을 특정 값을 설정하여 실험 하였다.\n",
        "그 값은 최적의 값이 였을까??"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxfz7tKoDcZQ"
      },
      "source": [
        "## 3) UMLE: Unsupervised Multi-discriminator Network for Low Light Enhancement [품질 향상]\n",
        "\n",
        "Low-light image enhancement, such as recovering color and texture details from low-light images, is a complex and vital task. For automated driving, low-light scenarios will have serious implications for vision-based applications. To address this problem, we propose a real-time unsupervised generative adversarial network (GAN) containing  <font color='red'><b>multiple discriminators, i.e. a multi-scale discriminator, a texture discriminator, and a color discriminator.</b></font>\n",
        "\n",
        "본 논문에서 loss function 은 Adversarial loss + Cycle loss + Color loss + Preserving Loss + Reconstruction loss 로 구성된다.\n",
        "\n",
        "$$ L_{all} = \\omega_1L_{adv}+\\omega_2L_{cyc}+\\omega_3L_{color}+\\omega_4L_{pre}+\\omega_5L_{idt}$$ \n",
        "\n",
        "하지만 각각의 omega는 huristic하게 특정 지었다. 최적화된 값인가??"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jbt0ApbS8V_Q"
      },
      "source": [
        "## 4) GENERATIVE MULTI-ADVERSARIAL NETWORKS [품질 향상+mode collapse]\n",
        "\n",
        "N개의 복수 discriminator를 사용하여 안정적으로 더 빠르게 GAN 학습을 할 수 있다. 또한 mode collapse에도 robust 한 특성을 보인다.\n",
        "\n",
        "본 논문에서는 loss function을 three classical Pythagorean means 을 응용하여 정의하였다.\n",
        "\n",
        "$$ AM_{soft}(V, \\lambda) = \\sum_{i}^N \\omega_iV_i $$\n",
        "$$ GM_{soft}(V, \\lambda) = -exp(\\sum_{i}^N \\omega_ilog(-V_i)) $$\n",
        "$$ HM_{soft}(V, \\lambda) = (\\sum_{i}^N \\omega_iV_i^{-1})^{-1} $$\n",
        "\n",
        "하지만, 논문에서는 omega에 대하여 다루지 않았다.\n",
        "저 omega는 어떻게 최적화 할 수 있겠는가?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5qpgtDUySyC"
      },
      "source": [
        "## 5) Dual Discriminator Generative Adversarial Nets [mode collapse]\n",
        "\n",
        "GAN에서 발생하는 치명적인 mode collapse (https://developers.google.com/machine-learning/gan/problems) 현상을 개선하기 위해 두개의 discriminator를 사용한다. - dual discriminator generative adversarial network (D2GAN)\n",
        "\n",
        "it combines <font color='red'><b>the Kullback-Leibler (KL) and reverse KL divergences</b></font> into a unified objective function, thus it exploits the complementary statistical properties from these divergences to effectively diversify the estimated density in capturing multi-modes.\n",
        "\n",
        "본 논문에서 제안하는 D2GAN의 목적함수는 다음과 같다.\n",
        "\n",
        "$$ \\min_{G} \\max_{D_1,D_2} J (G,D_1,D_2) = \\alpha \\times E_{x \\sim P_{data}} [logD_1 (x)] + E_{z \\sim P_z} [-D_1 (G(z))] + E_{x \\sim P_{data}}[-D_2 (x)] + \\beta \\times E_{z \\sim P_z} [logD_2 (G(z))] $$\n",
        "\n",
        "여기서 alpha, beta는 hyperparameter로서, 본 논문의 실험에서는 다양한 값을 대입하여 각각의 성능을 확인하였다.\n",
        "\n",
        "이렇게 값을 찾아야만 하는가?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBQHO9hOBho-"
      },
      "source": [
        "## 6) MD-GAN: Multi-Discriminator Generative Adversarial Networks for Distributed Datasets [성능 향상]\n",
        "\n",
        "we address the problem of distributing GANs so that they are able to train over datasets that are spread on multiple workers. MD-GAN is exposed as the first solution for this problem: we propose a novel learning procedure for GANs\n",
        "so that they fit this distributed setup. We then compare the performance of MD-GAN to an adapted version of Federated Learning to GANs, using the MNIST and CIFAR10 datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPUM8QvQCWzi"
      },
      "source": [
        "## 7) ParallelWasserstein Generative Adversarial Nets with Multiple Discriminators [성능 향상]\n",
        "\n",
        "In this paper, we solve the computation cost problem by speeding up the Wasserstein GANs from a welldesigned communication efficient parallel architecture. 그리고 이것을 Multiple Discriminators 로 구성하였다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjztFvs812EB"
      },
      "source": [
        "# 4. Proposed methods\n",
        "\n",
        "ref : https://realpython.com/python-ai-neural-network/\n",
        "\n",
        "\n",
        "\n",
        "colab 수식입력 : \n",
        "\n",
        "https://wikidocs.net/1679\n",
        "\n",
        "https://en.wikipedia.org/wiki/Help:Displaying_a_formula#Formatting_using_TeX\n",
        "\n",
        "Original GAN의 목적함수\n",
        "$$ \\min_{G}\\max_{D} V(D,G) = E_{x\\sim p_{data}(x)}[logD(x)] + E_{z\\sim p_{z}(z)}[log(1-D(G(z)))] $$\n",
        "\n",
        "Multi-Discriminator GAN은 discriminator가 각 목적에 의하여 여러개 (N개) 있다.\n",
        "MDGAN의 목적함수\n",
        "\n",
        "$$ \\min_{G}\\max_{D_{i\\sim N}} V(D_{i\\sim N},G) = \\sum_{i=1}^N \\{E_{x\\sim p_{data}(x)}[logD_i(x)] + E_{z\\sim p_{z}(z)}[log(1-D_i(G(z)))]\\} $$\n",
        "\n",
        "여기서\n",
        "\n",
        "$$ L(D_i,G) =  E_{x\\sim p_{data}(x)}[logD_i(x)] + E_{z\\sim p_{z}(z)}[log(1-D_i(G(z)))] $$\n",
        "\n",
        "이라하고 단순화 하면\n",
        "\n",
        "$$ \\min_{G}\\max_{D_{i\\sim N}} V(D_{i\\sim N},G) = \\sum_{i=1}^N L(D_i,G) $$\n",
        "\n",
        "와 같이 된다.\n",
        "\n",
        "문제점은 GAN의 특성상, 특정 Discriminator가 학습에 있어 지배적으로 loss 함수에 영향을 미치게 되어 각각의 Discriminator가 골고루 학습에 참여하지 못하고 의도하지 않은 결과를 만들게 된다. 이러한 문제점을 극복하기 위해 다음의 두가지 제안을 한다.\n",
        "\n",
        "1) 목적함수에 각 Loss 에 대한 표준편차 (standard-deviation) 를 반영하여 각 Discriminator에 대한 Loss가 상호 유사한 수준을 유지하면 학습이 진행되도록 한다.\n",
        "\n",
        "$$ \\min_{G}\\max_{D_{i\\sim N}} V(D_{i\\sim N},G) = \\sum_{i=1}^N L(D_i,G) + \\sigma(L(D_i,G))$$\n",
        "\n",
        "2) 각 discriminator에 의한 loss를 제어하기 위해, adaptive discriminant factor (ADF) 를 적용하고, 학습의 진행 과정에서 이를 최적화 한다. \n",
        "\n",
        "$$ \\min_{G}\\max_{D_{i\\sim N}} V(\\lambda_{i\\sim N},D_{i\\sim N},G) = \\sum_{i=1}^N \\lambda_iL(D_i,G)$$\n",
        "\n",
        "3) 1)의 제안에 2)의 제안을 추가한다.\n",
        "\n",
        "$$ \\min_{G}\\max_{D_{i\\sim N}} V(\\lambda_{i\\sim N},D_{i\\sim N},G) = \\sum_{i=1}^N \\lambda_iL(D_i,G) + \\sigma(L(D_i,G))$$\n",
        "\n",
        "\n",
        "여기서\n",
        "\n",
        "$$ \\lambda_i = adaptive\\ discriminant \\ factor \\ for \\ discriminator \\ i  $$\n",
        "\n",
        "중요한 것은, 학습과정에서 L_i을 작게 (학습의 방향)하기 위해서는 lambda_i는 역으로 커져야 한다. 그래야, 전체 Loss function에서 비중이 증대되어 더 적극적인 학습이 이루어 지게 된다. 따라서, lambda_i의 최적화 방향은 기존의 gradient decent와 반대 방향이 되어야 한다.\n",
        "\n",
        "$$ \\lambda_i^{t+1} = \\lambda_i^t + \\gamma \\nabla V(\\lambda_{i\\sim N}^t,D_{i\\sim N},G)$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K87VNBbeRLFF"
      },
      "source": [
        "#5. Experiment\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGovNR_uVJFB"
      },
      "source": [
        "실험은 CIFAR-10의 GAN 생성에서, N개의 Discriminator를 사용하며, 위의 3가지 제안을 각각 적용하여 Inception score 를 측정한다\n",
        "\n",
        "https://machinelearningmastery.com/how-to-implement-the-inception-score-from-scratch-for-evaluating-generated-images/\n",
        "\n",
        "https://github.com/hvy/chainer-inception-score\n",
        "\n",
        "https://colab.research.google.com/github/ssundar6087/vision-and-words/blob/master/_notebooks/2020-05-01-DCGAN-CIFAR10.ipynb\n",
        "\n",
        "https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJelZOUbelwt"
      },
      "source": [
        "## Requirements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQhaYsGRCxhZ",
        "outputId": "a2dc938c-6683-41c2-e4f4-3970ac742fd7"
      },
      "source": [
        "\n",
        "if True:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlSzlVm_eqjZ",
        "outputId": "1c6b3b43-f41c-4193-e7d7-0097c8ceb978"
      },
      "source": [
        "#collapse-hide\n",
        "#Author: Sairam Sundaresan\n",
        "#Version: 1.0\n",
        "#Date May 1, 2020\n",
        "# Preliminaries\n",
        "# WandB – Install the W&B library\n",
        "%pip install wandb -q"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.8MB 15.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 11.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 133kB 54.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 174kB 53.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 9.2MB/s \n",
            "\u001b[?25h  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        },
        "id": "PuCPVP4wetwa",
        "outputId": "5fc4b504-860b-440c-f089-57eab54bafb2"
      },
      "source": [
        "from __future__ import print_function\n",
        "import argparse\n",
        "import random # to set the python random seed\n",
        "%matplotlib inline\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from IPython.display import HTML\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.utils.data\n",
        "import torchvision.utils as vutils\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "# Ignore excessive warnings\n",
        "import logging\n",
        "logging.propagate = False \n",
        "logging.getLogger().setLevel(logging.ERROR)\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "manualSeed = 42\n",
        "random.seed(manualSeed)\n",
        "torch.manual_seed(manualSeed)\n",
        "\n",
        "# WandB – Import the wandb library\n",
        "import wandb\n",
        "wandb.login()\n",
        "wandb.init(project=\"dcgan\") # Change the project name based on your W & B account"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdolmani38\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.31<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">hopeful-glade-6</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/dolmani38/dcgan\" target=\"_blank\">https://wandb.ai/dolmani38/dcgan</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/dolmani38/dcgan/runs/2jz6kxga\" target=\"_blank\">https://wandb.ai/dolmani38/dcgan/runs/2jz6kxga</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210529_163833-2jz6kxga</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7f6ea5747350>"
            ],
            "text/html": [
              "<h1>Run(2jz6kxga)</h1><iframe src=\"https://wandb.ai/dolmani38/dcgan/runs/2jz6kxga\" style=\"border:none;width:100%;height:400px\"></iframe>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88tiJ_fGezW5"
      },
      "source": [
        "## Parameters of Interest\n",
        "Note that the Pytorch tutorial [referenced below](https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html) is designed for the **Celebrity faces** dataset and produces `64 x 64` images. I've tweaked the network architecture to produce `32 x 32` images as corresponding to the **CIFAR-10** dataset. The parameters below reflect the same. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PH2Syb9yewfR"
      },
      "source": [
        "# Number of workers for dataloader\n",
        "workers = 2\n",
        "\n",
        "# Batch size during training\n",
        "batch_size = 128\n",
        "\n",
        "# Spatial size of training images. All images will be resized to this\n",
        "#   size using a transformer.\n",
        "image_size = 32\n",
        "\n",
        "# Number of channels in the training images. For color images this is 3\n",
        "nc = 3\n",
        "\n",
        "# Size of z latent vector (i.e. size of generator input)\n",
        "nz = 100\n",
        "\n",
        "# Size of feature maps in generator\n",
        "ngf = 64\n",
        "\n",
        "# Size of feature maps in discriminator\n",
        "ndf = 64\n",
        "\n",
        "# Number of training epochs\n",
        "num_epochs = 100\n",
        "\n",
        "# Learning rate for optimizers\n",
        "lr = 0.0002\n",
        "\n",
        "# Beta1 hyperparam for Adam optimizers\n",
        "beta1 = 0.5\n",
        "\n",
        "# Number of GPUs available. Use 0 for CPU mode.\n",
        "ngpu = 1"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9xLvwOGe3Me"
      },
      "source": [
        "## Model Definition\n",
        "Let's define a generator and discriminator first. Weight initialization is a key factor in being able to produce a decent GAN and as per the paper, the weights are drawn from a _normal_ distribution with `0` mean and a standard-deviation of `0.02`. Also note that unlike in the original pytorch tutorial, I've removed one layer from the generator (at the end) and from the discriminator (at the beginning) to accomodate the CIFAR-10 dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48qcc0Mke4-C"
      },
      "source": [
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIdITkPLe78S"
      },
      "source": [
        "# Generator\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, ngpu):\n",
        "        super(Generator, self).__init__()\n",
        "        self.ngpu = ngpu\n",
        "        self.main = nn.Sequential(\n",
        "            nn.ConvTranspose2d( nz, ngf * 8, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 8),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 4),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 2),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d( ngf * 2, nc, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aS-V8MgMe8wu"
      },
      "source": [
        "# Discriminator\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, ngpu):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.ngpu = ngpu\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf * 4, 1, 4, 1, 0, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgG3zeQhe-5e"
      },
      "source": [
        "## Defining the Training Function\n",
        "The training function first trains the discriminator and then the generator as shown below. Note that by setting the real label value to `0.9` and the fake label value to `0.1`, I've applied label smoothing which has been shown to improve the results produced by the GAN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYj9LfvufAuK"
      },
      "source": [
        "def train(args, gen, disc, device, dataloader, optimizerG, optimizerD, criterion, epoch, iters):\n",
        "  gen.train()\n",
        "  disc.train()\n",
        "  img_list = []\n",
        "  fixed_noise = torch.randn(64, config.nz, 1, 1, device=device)\n",
        "\n",
        "  # Establish convention for real and fake labels during training (with label smoothing)\n",
        "  real_label = 0.9\n",
        "  fake_label = 0.1\n",
        "  for i, data in enumerate(dataloader, 0):\n",
        "\n",
        "      #*****\n",
        "      # Update Discriminator\n",
        "      #*****\n",
        "      ## Train with all-real batch\n",
        "      disc.zero_grad()\n",
        "      # Format batch\n",
        "      real_cpu = data[0].to(device)\n",
        "      b_size = real_cpu.size(0)\n",
        "      label = torch.full((b_size,), real_label, device=device)\n",
        "      # Forward pass real batch through D\n",
        "      output = disc(real_cpu).view(-1)\n",
        "      # Calculate loss on all-real batch\n",
        "      errD_real = criterion(output, label)\n",
        "      # Calculate gradients for D in backward pass\n",
        "      errD_real.backward()\n",
        "      D_x = output.mean().item()\n",
        "\n",
        "      ## Train with all-fake batch\n",
        "      # Generate batch of latent vectors\n",
        "      noise = torch.randn(b_size, config.nz, 1, 1, device=device)\n",
        "      # Generate fake image batch with G\n",
        "      fake = gen(noise)\n",
        "      label.fill_(fake_label)\n",
        "      # Classify all fake batch with D\n",
        "      output = disc(fake.detach()).view(-1)\n",
        "      # Calculate D's loss on the all-fake batch\n",
        "      errD_fake = criterion(output, label)\n",
        "      # Calculate the gradients for this batch\n",
        "      errD_fake.backward()\n",
        "      D_G_z1 = output.mean().item()\n",
        "      # Add the gradients from the all-real and all-fake batches\n",
        "      errD = errD_real + errD_fake\n",
        "      # Update D\n",
        "      optimizerD.step()\n",
        "\n",
        "      #*****\n",
        "      # Update Generator\n",
        "      #*****\n",
        "      gen.zero_grad()\n",
        "      label.fill_(real_label)  # fake labels are real for generator cost\n",
        "      # Since we just updated D, perform another forward pass of all-fake batch through D\n",
        "      output = disc(fake).view(-1)\n",
        "      # Calculate G's loss based on this output\n",
        "      errG = criterion(output, label)\n",
        "      # Calculate gradients for G\n",
        "      errG.backward()\n",
        "      D_G_z2 = output.mean().item()\n",
        "      # Update G\n",
        "      optimizerG.step()\n",
        "\n",
        "      # Output training stats\n",
        "      if i % 50 == 0:\n",
        "          print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
        "                % (epoch, args.epochs, i, len(dataloader),\n",
        "                    errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
        "          wandb.log({\n",
        "              \"Gen Loss\": errG.item(),\n",
        "              \"Disc Loss\": errD.item()})\n",
        "\n",
        "      # Check how the generator is doing by saving G's output on fixed_noise\n",
        "      if (iters % 500 == 0) or ((epoch == args.epochs-1) and (i == len(dataloader)-1)):\n",
        "          with torch.no_grad():\n",
        "              fake = gen(fixed_noise).detach().cpu()\n",
        "          img_list.append(wandb.Image(vutils.make_grid(fake, padding=2, normalize=True)))\n",
        "          wandb.log({\n",
        "              \"Generated Images\": img_list})\n",
        "      iters += 1"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZAHrsFMfI2R"
      },
      "source": [
        "## Monitoring the Run\n",
        "Once we have all the pieces in place, all we need to do is train the model and watch it learn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkUXUZebfCYo",
        "outputId": "be453e2d-b240-4fd7-d754-17385b35fe49"
      },
      "source": [
        "#hide-collapse\n",
        "wandb.watch_called = False \n",
        "# WandB – Config is a variable that holds and saves hyperparameters and inputs\n",
        "config = wandb.config          # Initialize config\n",
        "config.batch_size = batch_size \n",
        "config.epochs = num_epochs         \n",
        "config.lr = lr              \n",
        "config.beta1 = beta1\n",
        "config.nz = nz          \n",
        "config.no_cuda = False         \n",
        "config.seed = manualSeed # random seed (default: 42)\n",
        "config.log_interval = 10 # how many batches to wait before logging training status\n",
        "\n",
        "use_cuda = not config.no_cuda and torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "\n",
        "# Set random seeds and deterministic pytorch for reproducibility\n",
        "random.seed(config.seed)       # python random seed\n",
        "torch.manual_seed(config.seed) # pytorch random seed\n",
        "np.random.seed(config.seed) # numpy random seed\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "# Load the dataset\n",
        "transform = transforms.Compose(\n",
        "    [transforms.Scale(32),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=config.batch_size,\n",
        "                                            shuffle=True, num_workers=workers)\n",
        "\n",
        "# Create the generator\n",
        "netG = Generator(ngpu).to(device)\n",
        "\n",
        "do_train = True\n",
        "\n",
        "if do_train:\n",
        "\n",
        "    # Handle multi-gpu if desired\n",
        "    if (device.type == 'cuda') and (ngpu > 1):\n",
        "        netG = nn.DataParallel(netG, list(range(ngpu)))\n",
        "\n",
        "    # Apply the weights_init function to randomly initialize all weights\n",
        "    #  to mean=0, stdev=0.2.\n",
        "    netG.apply(weights_init)\n",
        "\n",
        "    # Create the Discriminator\n",
        "    netD = Discriminator(ngpu).to(device)\n",
        "\n",
        "    # Handle multi-gpu if desired\n",
        "    if (device.type == 'cuda') and (ngpu > 1):\n",
        "        netD = nn.DataParallel(netD, list(range(ngpu)))\n",
        "\n",
        "    # Apply the weights_init function to randomly initialize all weights\n",
        "    #  to mean=0, stdev=0.2.\n",
        "    netD.apply(weights_init)\n",
        "\n",
        "    # Initialize BCELoss function\n",
        "    criterion = nn.BCELoss()\n",
        "\n",
        "    # Setup Adam optimizers for both G and D\n",
        "    optimizerD = optim.Adam(netD.parameters(), lr=config.lr, betas=(config.beta1, 0.999))\n",
        "    optimizerG = optim.Adam(netG.parameters(), lr=config.lr, betas=(config.beta1, 0.999))\n",
        "\n",
        "    # WandB – wandb.watch() automatically fetches all layer dimensions, gradients, model parameters and logs them automatically to your dashboard.\n",
        "    # Using log=\"all\" log histograms of parameter values in addition to gradients\n",
        "    wandb.watch(netG, log=\"all\")\n",
        "    wandb.watch(netD, log=\"all\")\n",
        "    iters = 0\n",
        "    for epoch in range(1, config.epochs + 1):\n",
        "        train(config, netG, netD, device, trainloader, optimizerG, optimizerD, criterion, epoch, iters)\n",
        "        \n",
        "    # WandB – Save the model checkpoint. This automatically saves a file to the cloud and associates it with the current run.\n",
        "    torch.save(netG.state_dict(), \"/content/drive/MyDrive/AMD-GAN/CIFAR10_GAN_model/model.h5\")\n",
        "    #wandb.save('/content/drive/MyDrive/AMD-GAN/CIFAR10_GAN_model/model.h5')\n",
        "\n",
        "    gen = netG\n",
        "    gen.eval()\n",
        "else:\n",
        "    # Create the generator\n",
        "    gen = Generator(ngpu).to(device)\n",
        "    gen.load_state_dict(torch.load('/content/drive/MyDrive/AMD-GAN/CIFAR10_GAN_model/model.h5'))\n",
        "    gen.eval()\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:285: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
            "  warnings.warn(\"The use of the transforms.Scale transform is deprecated, \" +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "[1/100][0/391]\tLoss_D: 1.8011\tLoss_G: 1.2655\tD(x): 0.3113\tD(G(z)): 0.3837 / 0.2868\n",
            "[1/100][50/391]\tLoss_D: 0.9177\tLoss_G: 4.3246\tD(x): 0.7232\tD(G(z)): 0.2691 / 0.0098\n",
            "[1/100][100/391]\tLoss_D: 0.6980\tLoss_G: 2.0994\tD(x): 0.8635\tD(G(z)): 0.0985 / 0.1032\n",
            "[1/100][150/391]\tLoss_D: 0.9581\tLoss_G: 2.3060\tD(x): 0.6782\tD(G(z)): 0.2138 / 0.0864\n",
            "[1/100][200/391]\tLoss_D: 0.9465\tLoss_G: 1.7895\tD(x): 0.6808\tD(G(z)): 0.2728 / 0.1521\n",
            "[1/100][250/391]\tLoss_D: 0.8297\tLoss_G: 2.4752\tD(x): 0.7061\tD(G(z)): 0.1625 / 0.0717\n",
            "[1/100][300/391]\tLoss_D: 0.8131\tLoss_G: 2.5545\tD(x): 0.8225\tD(G(z)): 0.2451 / 0.0636\n",
            "[1/100][350/391]\tLoss_D: 1.0724\tLoss_G: 1.3907\tD(x): 0.5900\tD(G(z)): 0.2899 / 0.2412\n",
            "[2/100][0/391]\tLoss_D: 1.3085\tLoss_G: 1.6221\tD(x): 0.6621\tD(G(z)): 0.5089 / 0.2035\n",
            "[2/100][50/391]\tLoss_D: 1.0224\tLoss_G: 1.5641\tD(x): 0.5870\tD(G(z)): 0.2385 / 0.1950\n",
            "[2/100][100/391]\tLoss_D: 1.3698\tLoss_G: 1.6569\tD(x): 0.4601\tD(G(z)): 0.3528 / 0.1786\n",
            "[2/100][150/391]\tLoss_D: 0.9231\tLoss_G: 1.6582\tD(x): 0.6672\tD(G(z)): 0.2373 / 0.1816\n",
            "[2/100][200/391]\tLoss_D: 1.5554\tLoss_G: 1.6853\tD(x): 0.3568\tD(G(z)): 0.0317 / 0.1789\n",
            "[2/100][250/391]\tLoss_D: 1.0014\tLoss_G: 2.5649\tD(x): 0.7113\tD(G(z)): 0.3470 / 0.0711\n",
            "[2/100][300/391]\tLoss_D: 0.7955\tLoss_G: 2.0864\tD(x): 0.7956\tD(G(z)): 0.2306 / 0.1116\n",
            "[2/100][350/391]\tLoss_D: 0.8541\tLoss_G: 1.8908\tD(x): 0.7069\tD(G(z)): 0.1919 / 0.1409\n",
            "[3/100][0/391]\tLoss_D: 0.8275\tLoss_G: 2.0123\tD(x): 0.7882\tD(G(z)): 0.2425 / 0.1300\n",
            "[3/100][50/391]\tLoss_D: 0.8505\tLoss_G: 2.3419\tD(x): 0.7909\tD(G(z)): 0.2842 / 0.0908\n",
            "[3/100][100/391]\tLoss_D: 0.8909\tLoss_G: 2.0730\tD(x): 0.7598\tD(G(z)): 0.2726 / 0.1200\n",
            "[3/100][150/391]\tLoss_D: 0.8979\tLoss_G: 2.1610\tD(x): 0.7742\tD(G(z)): 0.3108 / 0.1090\n",
            "[3/100][200/391]\tLoss_D: 1.0675\tLoss_G: 1.2670\tD(x): 0.5651\tD(G(z)): 0.2380 / 0.2847\n",
            "[3/100][250/391]\tLoss_D: 0.9541\tLoss_G: 1.4582\tD(x): 0.6650\tD(G(z)): 0.2472 / 0.2286\n",
            "[3/100][300/391]\tLoss_D: 1.0031\tLoss_G: 1.8166\tD(x): 0.6147\tD(G(z)): 0.2427 / 0.1576\n",
            "[3/100][350/391]\tLoss_D: 1.4292\tLoss_G: 1.3234\tD(x): 0.4821\tD(G(z)): 0.3927 / 0.2717\n",
            "[4/100][0/391]\tLoss_D: 1.0548\tLoss_G: 1.6513\tD(x): 0.7833\tD(G(z)): 0.4573 / 0.1784\n",
            "[4/100][50/391]\tLoss_D: 1.1021\tLoss_G: 1.1452\tD(x): 0.6105\tD(G(z)): 0.3560 / 0.3162\n",
            "[4/100][100/391]\tLoss_D: 0.9093\tLoss_G: 2.0265\tD(x): 0.7347\tD(G(z)): 0.2937 / 0.1226\n",
            "[4/100][150/391]\tLoss_D: 0.9019\tLoss_G: 1.5047\tD(x): 0.7097\tD(G(z)): 0.2745 / 0.2124\n",
            "[4/100][200/391]\tLoss_D: 1.1108\tLoss_G: 2.4617\tD(x): 0.8056\tD(G(z)): 0.4776 / 0.0792\n",
            "[4/100][250/391]\tLoss_D: 0.8815\tLoss_G: 1.8761\tD(x): 0.7731\tD(G(z)): 0.2741 / 0.1441\n",
            "[4/100][300/391]\tLoss_D: 0.8666\tLoss_G: 1.5903\tD(x): 0.7111\tD(G(z)): 0.2182 / 0.1987\n",
            "[4/100][350/391]\tLoss_D: 0.9088\tLoss_G: 1.4965\tD(x): 0.6531\tD(G(z)): 0.1809 / 0.2163\n",
            "[5/100][0/391]\tLoss_D: 1.0665\tLoss_G: 1.6041\tD(x): 0.6252\tD(G(z)): 0.3245 / 0.1926\n",
            "[5/100][50/391]\tLoss_D: 0.9692\tLoss_G: 2.0617\tD(x): 0.7683\tD(G(z)): 0.3659 / 0.1205\n",
            "[5/100][100/391]\tLoss_D: 0.8982\tLoss_G: 2.2917\tD(x): 0.8012\tD(G(z)): 0.3412 / 0.0924\n",
            "[5/100][150/391]\tLoss_D: 0.8834\tLoss_G: 2.2936\tD(x): 0.8082\tD(G(z)): 0.3281 / 0.0957\n",
            "[5/100][200/391]\tLoss_D: 1.0823\tLoss_G: 1.5750\tD(x): 0.6458\tD(G(z)): 0.3658 / 0.1987\n",
            "[5/100][250/391]\tLoss_D: 1.0134\tLoss_G: 2.1585\tD(x): 0.7244\tD(G(z)): 0.3818 / 0.1077\n",
            "[5/100][300/391]\tLoss_D: 1.0136\tLoss_G: 2.0943\tD(x): 0.7711\tD(G(z)): 0.4095 / 0.1146\n",
            "[5/100][350/391]\tLoss_D: 1.1678\tLoss_G: 1.9095\tD(x): 0.7658\tD(G(z)): 0.5037 / 0.1371\n",
            "[6/100][0/391]\tLoss_D: 0.9977\tLoss_G: 2.3623\tD(x): 0.7981\tD(G(z)): 0.4176 / 0.0870\n",
            "[6/100][50/391]\tLoss_D: 1.0397\tLoss_G: 1.5348\tD(x): 0.6487\tD(G(z)): 0.3396 / 0.2043\n",
            "[6/100][100/391]\tLoss_D: 1.0480\tLoss_G: 1.5036\tD(x): 0.7107\tD(G(z)): 0.4001 / 0.2162\n",
            "[6/100][150/391]\tLoss_D: 0.9750\tLoss_G: 1.7403\tD(x): 0.7903\tD(G(z)): 0.3985 / 0.1640\n",
            "[6/100][200/391]\tLoss_D: 1.1163\tLoss_G: 1.0703\tD(x): 0.6023\tD(G(z)): 0.3668 / 0.3395\n",
            "[6/100][250/391]\tLoss_D: 0.9945\tLoss_G: 1.5618\tD(x): 0.6810\tD(G(z)): 0.3291 / 0.2000\n",
            "[6/100][300/391]\tLoss_D: 1.0074\tLoss_G: 1.3618\tD(x): 0.6411\tD(G(z)): 0.2947 / 0.2529\n",
            "[6/100][350/391]\tLoss_D: 0.9286\tLoss_G: 1.4802\tD(x): 0.7203\tD(G(z)): 0.3161 / 0.2160\n",
            "[7/100][0/391]\tLoss_D: 1.0394\tLoss_G: 1.4084\tD(x): 0.6677\tD(G(z)): 0.3517 / 0.2377\n",
            "[7/100][50/391]\tLoss_D: 0.9319\tLoss_G: 1.5638\tD(x): 0.7453\tD(G(z)): 0.3453 / 0.1940\n",
            "[7/100][100/391]\tLoss_D: 1.0492\tLoss_G: 1.2821\tD(x): 0.5909\tD(G(z)): 0.2669 / 0.2772\n",
            "[7/100][150/391]\tLoss_D: 1.0423\tLoss_G: 1.8635\tD(x): 0.7603\tD(G(z)): 0.4322 / 0.1432\n",
            "[7/100][200/391]\tLoss_D: 1.0205\tLoss_G: 2.0548\tD(x): 0.6852\tD(G(z)): 0.3541 / 0.1182\n",
            "[7/100][250/391]\tLoss_D: 1.0039\tLoss_G: 1.3118\tD(x): 0.6436\tD(G(z)): 0.3084 / 0.2639\n",
            "[7/100][300/391]\tLoss_D: 1.0785\tLoss_G: 0.8896\tD(x): 0.5325\tD(G(z)): 0.1670 / 0.4236\n",
            "[7/100][350/391]\tLoss_D: 0.8832\tLoss_G: 1.4285\tD(x): 0.6992\tD(G(z)): 0.2387 / 0.2273\n",
            "[8/100][0/391]\tLoss_D: 1.2110\tLoss_G: 1.2548\tD(x): 0.4437\tD(G(z)): 0.1607 / 0.2862\n",
            "[8/100][50/391]\tLoss_D: 1.0753\tLoss_G: 1.3535\tD(x): 0.5977\tD(G(z)): 0.2927 / 0.2571\n",
            "[8/100][100/391]\tLoss_D: 0.9355\tLoss_G: 1.8675\tD(x): 0.7607\tD(G(z)): 0.3531 / 0.1448\n",
            "[8/100][150/391]\tLoss_D: 1.1269\tLoss_G: 1.2620\tD(x): 0.6073\tD(G(z)): 0.3796 / 0.2726\n",
            "[8/100][200/391]\tLoss_D: 1.2476\tLoss_G: 0.9591\tD(x): 0.4599\tD(G(z)): 0.2688 / 0.3855\n",
            "[8/100][250/391]\tLoss_D: 1.0906\tLoss_G: 1.4795\tD(x): 0.6709\tD(G(z)): 0.4059 / 0.2163\n",
            "[8/100][300/391]\tLoss_D: 1.0480\tLoss_G: 1.4048\tD(x): 0.5705\tD(G(z)): 0.2367 / 0.2369\n",
            "[8/100][350/391]\tLoss_D: 1.0797\tLoss_G: 1.6255\tD(x): 0.7501\tD(G(z)): 0.4590 / 0.1851\n",
            "[9/100][0/391]\tLoss_D: 1.3849\tLoss_G: 0.7046\tD(x): 0.3585\tD(G(z)): 0.1604 / 0.5155\n",
            "[9/100][50/391]\tLoss_D: 1.0245\tLoss_G: 1.2513\tD(x): 0.6076\tD(G(z)): 0.2890 / 0.2757\n",
            "[9/100][100/391]\tLoss_D: 0.9117\tLoss_G: 1.5983\tD(x): 0.6844\tD(G(z)): 0.2600 / 0.1909\n",
            "[9/100][150/391]\tLoss_D: 1.4074\tLoss_G: 1.5711\tD(x): 0.7242\tD(G(z)): 0.5941 / 0.2044\n",
            "[9/100][200/391]\tLoss_D: 1.0207\tLoss_G: 1.6663\tD(x): 0.7684\tD(G(z)): 0.4187 / 0.1785\n",
            "[9/100][250/391]\tLoss_D: 1.0030\tLoss_G: 1.4607\tD(x): 0.7451\tD(G(z)): 0.3950 / 0.2225\n",
            "[9/100][300/391]\tLoss_D: 1.0218\tLoss_G: 1.2075\tD(x): 0.5786\tD(G(z)): 0.2443 / 0.2967\n",
            "[9/100][350/391]\tLoss_D: 1.0577\tLoss_G: 1.4015\tD(x): 0.5859\tD(G(z)): 0.2822 / 0.2401\n",
            "[10/100][0/391]\tLoss_D: 1.0521\tLoss_G: 1.5030\tD(x): 0.6980\tD(G(z)): 0.4033 / 0.2127\n",
            "[10/100][50/391]\tLoss_D: 1.0325\tLoss_G: 1.2808\tD(x): 0.6152\tD(G(z)): 0.3114 / 0.2671\n",
            "[10/100][100/391]\tLoss_D: 0.9309\tLoss_G: 2.0737\tD(x): 0.8413\tD(G(z)): 0.3980 / 0.1133\n",
            "[10/100][150/391]\tLoss_D: 1.0434\tLoss_G: 1.5961\tD(x): 0.7229\tD(G(z)): 0.4122 / 0.1908\n",
            "[10/100][200/391]\tLoss_D: 1.2469\tLoss_G: 0.8057\tD(x): 0.4501\tD(G(z)): 0.2522 / 0.4575\n",
            "[10/100][250/391]\tLoss_D: 1.1382\tLoss_G: 1.1353\tD(x): 0.5085\tD(G(z)): 0.2569 / 0.3148\n",
            "[10/100][300/391]\tLoss_D: 0.9945\tLoss_G: 1.3030\tD(x): 0.6711\tD(G(z)): 0.3383 / 0.2643\n",
            "[10/100][350/391]\tLoss_D: 1.1060\tLoss_G: 1.4034\tD(x): 0.6393\tD(G(z)): 0.4005 / 0.2316\n",
            "[11/100][0/391]\tLoss_D: 1.1121\tLoss_G: 1.1331\tD(x): 0.5788\tD(G(z)): 0.3353 / 0.3205\n",
            "[11/100][50/391]\tLoss_D: 1.1289\tLoss_G: 1.0549\tD(x): 0.5363\tD(G(z)): 0.2734 / 0.3455\n",
            "[11/100][100/391]\tLoss_D: 1.0155\tLoss_G: 1.3881\tD(x): 0.5914\tD(G(z)): 0.2610 / 0.2362\n",
            "[11/100][150/391]\tLoss_D: 0.9852\tLoss_G: 1.4757\tD(x): 0.7527\tD(G(z)): 0.3996 / 0.2147\n",
            "[11/100][200/391]\tLoss_D: 1.1103\tLoss_G: 1.0780\tD(x): 0.5339\tD(G(z)): 0.2491 / 0.3372\n",
            "[11/100][250/391]\tLoss_D: 1.5591\tLoss_G: 2.3527\tD(x): 0.8832\tD(G(z)): 0.6790 / 0.0926\n",
            "[11/100][300/391]\tLoss_D: 1.1086\tLoss_G: 1.4798\tD(x): 0.6896\tD(G(z)): 0.4305 / 0.2223\n",
            "[11/100][350/391]\tLoss_D: 1.0348\tLoss_G: 1.1543\tD(x): 0.5899\tD(G(z)): 0.2594 / 0.3154\n",
            "[12/100][0/391]\tLoss_D: 1.2481\tLoss_G: 1.8762\tD(x): 0.7947\tD(G(z)): 0.5695 / 0.1451\n",
            "[12/100][50/391]\tLoss_D: 0.9525\tLoss_G: 1.7363\tD(x): 0.7296\tD(G(z)): 0.3513 / 0.1655\n",
            "[12/100][100/391]\tLoss_D: 1.0433\tLoss_G: 1.2003\tD(x): 0.6387\tD(G(z)): 0.3436 / 0.2908\n",
            "[12/100][150/391]\tLoss_D: 1.0489\tLoss_G: 1.1081\tD(x): 0.6065\tD(G(z)): 0.3245 / 0.3186\n",
            "[12/100][200/391]\tLoss_D: 1.0495\tLoss_G: 1.8619\tD(x): 0.7415\tD(G(z)): 0.4297 / 0.1401\n",
            "[12/100][250/391]\tLoss_D: 1.0008\tLoss_G: 1.4006\tD(x): 0.6296\tD(G(z)): 0.2897 / 0.2350\n",
            "[12/100][300/391]\tLoss_D: 1.0561\tLoss_G: 1.2056\tD(x): 0.6132\tD(G(z)): 0.3334 / 0.2892\n",
            "[12/100][350/391]\tLoss_D: 1.1296\tLoss_G: 2.0898\tD(x): 0.7778\tD(G(z)): 0.4990 / 0.1136\n",
            "[13/100][0/391]\tLoss_D: 1.1204\tLoss_G: 1.4186\tD(x): 0.6761\tD(G(z)): 0.4341 / 0.2343\n",
            "[13/100][50/391]\tLoss_D: 1.2595\tLoss_G: 1.3953\tD(x): 0.7229\tD(G(z)): 0.5470 / 0.2424\n",
            "[13/100][100/391]\tLoss_D: 0.9954\tLoss_G: 1.1711\tD(x): 0.6249\tD(G(z)): 0.2919 / 0.2998\n",
            "[13/100][150/391]\tLoss_D: 1.2494\tLoss_G: 1.0560\tD(x): 0.4222\tD(G(z)): 0.1726 / 0.3544\n",
            "[13/100][200/391]\tLoss_D: 1.1174\tLoss_G: 1.0980\tD(x): 0.5264\tD(G(z)): 0.2704 / 0.3292\n",
            "[13/100][250/391]\tLoss_D: 0.9276\tLoss_G: 1.8713\tD(x): 0.7820\tD(G(z)): 0.3620 / 0.1443\n",
            "[13/100][300/391]\tLoss_D: 1.0618\tLoss_G: 1.1956\tD(x): 0.6401\tD(G(z)): 0.3678 / 0.2921\n",
            "[13/100][350/391]\tLoss_D: 1.0629\tLoss_G: 1.4210\tD(x): 0.6835\tD(G(z)): 0.4014 / 0.2309\n",
            "[14/100][0/391]\tLoss_D: 0.9420\tLoss_G: 1.4016\tD(x): 0.6529\tD(G(z)): 0.2582 / 0.2398\n",
            "[14/100][50/391]\tLoss_D: 1.0490\tLoss_G: 1.0994\tD(x): 0.6149\tD(G(z)): 0.3166 / 0.3291\n",
            "[14/100][100/391]\tLoss_D: 1.0827\tLoss_G: 0.8911\tD(x): 0.5451\tD(G(z)): 0.2711 / 0.4087\n",
            "[14/100][150/391]\tLoss_D: 1.0909\tLoss_G: 1.1290\tD(x): 0.6125\tD(G(z)): 0.3512 / 0.3190\n",
            "[14/100][200/391]\tLoss_D: 1.3490\tLoss_G: 2.0565\tD(x): 0.8424\tD(G(z)): 0.6264 / 0.1180\n",
            "[14/100][250/391]\tLoss_D: 0.9558\tLoss_G: 1.2209\tD(x): 0.6999\tD(G(z)): 0.3258 / 0.2830\n",
            "[14/100][300/391]\tLoss_D: 1.2207\tLoss_G: 1.2415\tD(x): 0.6577\tD(G(z)): 0.4855 / 0.2814\n",
            "[14/100][350/391]\tLoss_D: 1.1209\tLoss_G: 1.0389\tD(x): 0.5145\tD(G(z)): 0.2315 / 0.3562\n",
            "[15/100][0/391]\tLoss_D: 1.1057\tLoss_G: 1.1949\tD(x): 0.5494\tD(G(z)): 0.2865 / 0.3016\n",
            "[15/100][50/391]\tLoss_D: 1.0556\tLoss_G: 1.4317\tD(x): 0.7087\tD(G(z)): 0.4175 / 0.2266\n",
            "[15/100][100/391]\tLoss_D: 1.4013\tLoss_G: 1.6953\tD(x): 0.7505\tD(G(z)): 0.6177 / 0.1735\n",
            "[15/100][150/391]\tLoss_D: 1.0811\tLoss_G: 1.3667\tD(x): 0.6605\tD(G(z)): 0.4011 / 0.2439\n",
            "[15/100][200/391]\tLoss_D: 1.1231\tLoss_G: 1.1294\tD(x): 0.6028\tD(G(z)): 0.3804 / 0.3146\n",
            "[15/100][250/391]\tLoss_D: 1.1704\tLoss_G: 1.5506\tD(x): 0.7300\tD(G(z)): 0.5049 / 0.1966\n",
            "[15/100][300/391]\tLoss_D: 1.0465\tLoss_G: 1.5833\tD(x): 0.7484\tD(G(z)): 0.4296 / 0.1935\n",
            "[15/100][350/391]\tLoss_D: 1.0944\tLoss_G: 1.1028\tD(x): 0.5453\tD(G(z)): 0.2728 / 0.3226\n",
            "[16/100][0/391]\tLoss_D: 1.2005\tLoss_G: 1.6825\tD(x): 0.7616\tD(G(z)): 0.5331 / 0.1753\n",
            "[16/100][50/391]\tLoss_D: 1.1760\tLoss_G: 1.4042\tD(x): 0.7018\tD(G(z)): 0.4897 / 0.2319\n",
            "[16/100][100/391]\tLoss_D: 1.0906\tLoss_G: 1.3794\tD(x): 0.7543\tD(G(z)): 0.4699 / 0.2385\n",
            "[16/100][150/391]\tLoss_D: 1.0346\tLoss_G: 1.5890\tD(x): 0.7485\tD(G(z)): 0.4242 / 0.1938\n",
            "[16/100][200/391]\tLoss_D: 1.1040\tLoss_G: 1.2980\tD(x): 0.7286\tD(G(z)): 0.4673 / 0.2596\n",
            "[16/100][250/391]\tLoss_D: 1.1279\tLoss_G: 1.5307\tD(x): 0.7463\tD(G(z)): 0.4832 / 0.2058\n",
            "[16/100][300/391]\tLoss_D: 1.0944\tLoss_G: 1.2501\tD(x): 0.6334\tD(G(z)): 0.3907 / 0.2724\n",
            "[16/100][350/391]\tLoss_D: 1.0384\tLoss_G: 1.3737\tD(x): 0.6863\tD(G(z)): 0.3917 / 0.2385\n",
            "[17/100][0/391]\tLoss_D: 1.1605\tLoss_G: 0.8404\tD(x): 0.4902\tD(G(z)): 0.2411 / 0.4427\n",
            "[17/100][50/391]\tLoss_D: 1.0453\tLoss_G: 1.1698\tD(x): 0.5650\tD(G(z)): 0.2579 / 0.2985\n",
            "[17/100][100/391]\tLoss_D: 1.1012\tLoss_G: 1.0420\tD(x): 0.5239\tD(G(z)): 0.2282 / 0.3541\n",
            "[17/100][150/391]\tLoss_D: 1.2921\tLoss_G: 1.5368\tD(x): 0.6869\tD(G(z)): 0.5440 / 0.2068\n",
            "[17/100][200/391]\tLoss_D: 1.1282\tLoss_G: 1.2818\tD(x): 0.6476\tD(G(z)): 0.4145 / 0.2690\n",
            "[17/100][250/391]\tLoss_D: 1.0109\tLoss_G: 1.5378\tD(x): 0.6814\tD(G(z)): 0.3653 / 0.2024\n",
            "[17/100][300/391]\tLoss_D: 1.0921\tLoss_G: 1.7478\tD(x): 0.7394\tD(G(z)): 0.4619 / 0.1631\n",
            "[17/100][350/391]\tLoss_D: 1.3975\tLoss_G: 0.7307\tD(x): 0.3656\tD(G(z)): 0.1765 / 0.5090\n",
            "[18/100][0/391]\tLoss_D: 1.0868\tLoss_G: 1.1799\tD(x): 0.5934\tD(G(z)): 0.3235 / 0.3006\n",
            "[18/100][50/391]\tLoss_D: 1.2924\tLoss_G: 1.4602\tD(x): 0.6880\tD(G(z)): 0.5499 / 0.2193\n",
            "[18/100][100/391]\tLoss_D: 1.0946\tLoss_G: 1.1338\tD(x): 0.6011\tD(G(z)): 0.3543 / 0.3128\n",
            "[18/100][150/391]\tLoss_D: 0.9603\tLoss_G: 1.3739\tD(x): 0.6488\tD(G(z)): 0.2773 / 0.2427\n",
            "[18/100][200/391]\tLoss_D: 1.0759\tLoss_G: 0.8299\tD(x): 0.5380\tD(G(z)): 0.2204 / 0.4611\n",
            "[18/100][250/391]\tLoss_D: 1.2424\tLoss_G: 1.1239\tD(x): 0.5369\tD(G(z)): 0.3935 / 0.3196\n",
            "[18/100][300/391]\tLoss_D: 1.3303\tLoss_G: 0.5131\tD(x): 0.3983\tD(G(z)): 0.2411 / 0.6491\n",
            "[18/100][350/391]\tLoss_D: 1.2137\tLoss_G: 1.4540\tD(x): 0.6991\tD(G(z)): 0.5090 / 0.2218\n",
            "[19/100][0/391]\tLoss_D: 1.2094\tLoss_G: 1.7306\tD(x): 0.7630\tD(G(z)): 0.5386 / 0.1710\n",
            "[19/100][50/391]\tLoss_D: 1.1595\tLoss_G: 1.7636\tD(x): 0.7522\tD(G(z)): 0.5072 / 0.1588\n",
            "[19/100][100/391]\tLoss_D: 1.1005\tLoss_G: 1.1004\tD(x): 0.6007\tD(G(z)): 0.3572 / 0.3257\n",
            "[19/100][150/391]\tLoss_D: 1.1075\tLoss_G: 1.5511\tD(x): 0.6812\tD(G(z)): 0.4314 / 0.2009\n",
            "[19/100][200/391]\tLoss_D: 1.1764\tLoss_G: 1.7410\tD(x): 0.7387\tD(G(z)): 0.5122 / 0.1654\n",
            "[19/100][250/391]\tLoss_D: 1.0583\tLoss_G: 1.3284\tD(x): 0.6506\tD(G(z)): 0.3653 / 0.2611\n",
            "[19/100][300/391]\tLoss_D: 1.0751\tLoss_G: 1.2763\tD(x): 0.6786\tD(G(z)): 0.4055 / 0.2679\n",
            "[19/100][350/391]\tLoss_D: 1.0852\tLoss_G: 1.0855\tD(x): 0.5770\tD(G(z)): 0.3199 / 0.3313\n",
            "[20/100][0/391]\tLoss_D: 1.3260\tLoss_G: 1.7782\tD(x): 0.7932\tD(G(z)): 0.6087 / 0.1580\n",
            "[20/100][50/391]\tLoss_D: 1.0854\tLoss_G: 1.1722\tD(x): 0.5429\tD(G(z)): 0.2641 / 0.3044\n",
            "[20/100][100/391]\tLoss_D: 1.0461\tLoss_G: 1.2501\tD(x): 0.7029\tD(G(z)): 0.4049 / 0.2752\n",
            "[20/100][150/391]\tLoss_D: 1.1163\tLoss_G: 1.1101\tD(x): 0.5352\tD(G(z)): 0.2733 / 0.3239\n",
            "[20/100][200/391]\tLoss_D: 1.0387\tLoss_G: 1.2760\tD(x): 0.6429\tD(G(z)): 0.3455 / 0.2764\n",
            "[20/100][250/391]\tLoss_D: 1.3014\tLoss_G: 2.0695\tD(x): 0.7867\tD(G(z)): 0.5925 / 0.1133\n",
            "[20/100][300/391]\tLoss_D: 1.0868\tLoss_G: 1.2023\tD(x): 0.5707\tD(G(z)): 0.3046 / 0.2931\n",
            "[20/100][350/391]\tLoss_D: 1.1911\tLoss_G: 0.9131\tD(x): 0.4689\tD(G(z)): 0.2247 / 0.4082\n",
            "[21/100][0/391]\tLoss_D: 1.1210\tLoss_G: 1.3761\tD(x): 0.6860\tD(G(z)): 0.4448 / 0.2400\n",
            "[21/100][50/391]\tLoss_D: 1.1078\tLoss_G: 1.5433\tD(x): 0.6574\tD(G(z)): 0.4227 / 0.1968\n",
            "[21/100][100/391]\tLoss_D: 1.1020\tLoss_G: 1.0212\tD(x): 0.6007\tD(G(z)): 0.3512 / 0.3554\n",
            "[21/100][150/391]\tLoss_D: 1.0882\tLoss_G: 1.1330\tD(x): 0.6001\tD(G(z)): 0.3399 / 0.3168\n",
            "[21/100][200/391]\tLoss_D: 1.0498\tLoss_G: 1.2466\tD(x): 0.6086\tD(G(z)): 0.3206 / 0.2759\n",
            "[21/100][250/391]\tLoss_D: 1.5583\tLoss_G: 0.9781\tD(x): 0.3068\tD(G(z)): 0.1783 / 0.3852\n",
            "[21/100][300/391]\tLoss_D: 1.1199\tLoss_G: 1.3389\tD(x): 0.6814\tD(G(z)): 0.4385 / 0.2523\n",
            "[21/100][350/391]\tLoss_D: 1.0291\tLoss_G: 1.1204\tD(x): 0.6681\tD(G(z)): 0.3678 / 0.3172\n",
            "[22/100][0/391]\tLoss_D: 1.1047\tLoss_G: 1.4361\tD(x): 0.7153\tD(G(z)): 0.4566 / 0.2275\n",
            "[22/100][50/391]\tLoss_D: 1.1570\tLoss_G: 1.2056\tD(x): 0.6088\tD(G(z)): 0.4056 / 0.2911\n",
            "[22/100][100/391]\tLoss_D: 1.1503\tLoss_G: 1.2253\tD(x): 0.6148\tD(G(z)): 0.4044 / 0.2879\n",
            "[22/100][150/391]\tLoss_D: 1.0449\tLoss_G: 1.4293\tD(x): 0.6785\tD(G(z)): 0.3905 / 0.2271\n",
            "[22/100][200/391]\tLoss_D: 1.0838\tLoss_G: 1.0024\tD(x): 0.5404\tD(G(z)): 0.2396 / 0.3647\n",
            "[22/100][250/391]\tLoss_D: 1.1056\tLoss_G: 1.0059\tD(x): 0.6324\tD(G(z)): 0.3936 / 0.3591\n",
            "[22/100][300/391]\tLoss_D: 1.5526\tLoss_G: 1.3048\tD(x): 0.5734\tD(G(z)): 0.5895 / 0.2711\n",
            "[22/100][350/391]\tLoss_D: 1.1835\tLoss_G: 0.9352\tD(x): 0.4725\tD(G(z)): 0.2295 / 0.3943\n",
            "[23/100][0/391]\tLoss_D: 1.2232\tLoss_G: 0.9188\tD(x): 0.4559\tD(G(z)): 0.2423 / 0.4033\n",
            "[23/100][50/391]\tLoss_D: 1.0447\tLoss_G: 1.3295\tD(x): 0.6394\tD(G(z)): 0.3549 / 0.2517\n",
            "[23/100][100/391]\tLoss_D: 1.1069\tLoss_G: 1.4528\tD(x): 0.6853\tD(G(z)): 0.4334 / 0.2203\n",
            "[23/100][150/391]\tLoss_D: 1.1784\tLoss_G: 1.3370\tD(x): 0.5833\tD(G(z)): 0.3986 / 0.2527\n",
            "[23/100][200/391]\tLoss_D: 1.0972\tLoss_G: 1.1691\tD(x): 0.5840\tD(G(z)): 0.3369 / 0.2990\n",
            "[23/100][250/391]\tLoss_D: 1.0487\tLoss_G: 1.3315\tD(x): 0.6869\tD(G(z)): 0.3920 / 0.2525\n",
            "[23/100][300/391]\tLoss_D: 1.1092\tLoss_G: 1.1749\tD(x): 0.5253\tD(G(z)): 0.2421 / 0.3070\n",
            "[23/100][350/391]\tLoss_D: 1.0736\tLoss_G: 1.3868\tD(x): 0.6773\tD(G(z)): 0.3995 / 0.2420\n",
            "[24/100][0/391]\tLoss_D: 1.4620\tLoss_G: 1.6231\tD(x): 0.7989\tD(G(z)): 0.6643 / 0.1924\n",
            "[24/100][50/391]\tLoss_D: 1.1078\tLoss_G: 1.2766\tD(x): 0.6214\tD(G(z)): 0.3820 / 0.2692\n",
            "[24/100][100/391]\tLoss_D: 1.0862\tLoss_G: 1.1853\tD(x): 0.6847\tD(G(z)): 0.4217 / 0.2939\n",
            "[24/100][150/391]\tLoss_D: 1.4361\tLoss_G: 0.7902\tD(x): 0.3459\tD(G(z)): 0.1559 / 0.4665\n",
            "[24/100][200/391]\tLoss_D: 1.0931\tLoss_G: 1.0484\tD(x): 0.5930\tD(G(z)): 0.3309 / 0.3508\n",
            "[24/100][250/391]\tLoss_D: 1.0938\tLoss_G: 1.3055\tD(x): 0.6622\tD(G(z)): 0.4082 / 0.2601\n",
            "[24/100][300/391]\tLoss_D: 1.0844\tLoss_G: 1.7826\tD(x): 0.8266\tD(G(z)): 0.4955 / 0.1569\n",
            "[24/100][350/391]\tLoss_D: 1.0344\tLoss_G: 1.2266\tD(x): 0.6478\tD(G(z)): 0.3494 / 0.2805\n",
            "[25/100][0/391]\tLoss_D: 1.6168\tLoss_G: 1.9645\tD(x): 0.8746\tD(G(z)): 0.7200 / 0.1348\n",
            "[25/100][50/391]\tLoss_D: 1.1412\tLoss_G: 1.1851\tD(x): 0.6080\tD(G(z)): 0.3898 / 0.2954\n",
            "[25/100][100/391]\tLoss_D: 1.0744\tLoss_G: 1.4143\tD(x): 0.6733\tD(G(z)): 0.4112 / 0.2286\n",
            "[25/100][150/391]\tLoss_D: 1.1378\tLoss_G: 1.4608\tD(x): 0.7197\tD(G(z)): 0.4817 / 0.2226\n",
            "[25/100][200/391]\tLoss_D: 1.0670\tLoss_G: 1.1630\tD(x): 0.6558\tD(G(z)): 0.3850 / 0.3024\n",
            "[25/100][250/391]\tLoss_D: 1.1151\tLoss_G: 1.7959\tD(x): 0.7882\tD(G(z)): 0.4908 / 0.1551\n",
            "[25/100][300/391]\tLoss_D: 1.0398\tLoss_G: 1.4512\tD(x): 0.6991\tD(G(z)): 0.3936 / 0.2291\n",
            "[25/100][350/391]\tLoss_D: 1.3511\tLoss_G: 0.9327\tD(x): 0.4779\tD(G(z)): 0.3976 / 0.3940\n",
            "[26/100][0/391]\tLoss_D: 1.0706\tLoss_G: 1.7222\tD(x): 0.7864\tD(G(z)): 0.4632 / 0.1675\n",
            "[26/100][50/391]\tLoss_D: 1.0234\tLoss_G: 1.4863\tD(x): 0.6813\tD(G(z)): 0.3731 / 0.2106\n",
            "[26/100][100/391]\tLoss_D: 1.1089\tLoss_G: 1.3700\tD(x): 0.6564\tD(G(z)): 0.4176 / 0.2470\n",
            "[26/100][150/391]\tLoss_D: 1.1104\tLoss_G: 1.2082\tD(x): 0.6646\tD(G(z)): 0.4186 / 0.2939\n",
            "[26/100][200/391]\tLoss_D: 0.9991\tLoss_G: 1.3129\tD(x): 0.5900\tD(G(z)): 0.2312 / 0.2651\n",
            "[26/100][250/391]\tLoss_D: 1.6367\tLoss_G: 1.0629\tD(x): 0.5888\tD(G(z)): 0.6237 / 0.3606\n",
            "[26/100][300/391]\tLoss_D: 1.0920\tLoss_G: 1.2406\tD(x): 0.6228\tD(G(z)): 0.3756 / 0.2801\n",
            "[26/100][350/391]\tLoss_D: 1.1902\tLoss_G: 1.2308\tD(x): 0.5483\tD(G(z)): 0.3697 / 0.2851\n",
            "[27/100][0/391]\tLoss_D: 1.0555\tLoss_G: 1.3110\tD(x): 0.6211\tD(G(z)): 0.3409 / 0.2589\n",
            "[27/100][50/391]\tLoss_D: 1.1105\tLoss_G: 1.1913\tD(x): 0.6258\tD(G(z)): 0.3955 / 0.2945\n",
            "[27/100][100/391]\tLoss_D: 1.1139\tLoss_G: 1.2475\tD(x): 0.6606\tD(G(z)): 0.4249 / 0.2740\n",
            "[27/100][150/391]\tLoss_D: 1.0649\tLoss_G: 1.2863\tD(x): 0.6336\tD(G(z)): 0.3587 / 0.2677\n",
            "[27/100][200/391]\tLoss_D: 1.1037\tLoss_G: 1.5060\tD(x): 0.6935\tD(G(z)): 0.4435 / 0.2082\n",
            "[27/100][250/391]\tLoss_D: 1.0677\tLoss_G: 1.1702\tD(x): 0.6027\tD(G(z)): 0.3253 / 0.2997\n",
            "[27/100][300/391]\tLoss_D: 1.1187\tLoss_G: 1.3306\tD(x): 0.6198\tD(G(z)): 0.3903 / 0.2553\n",
            "[27/100][350/391]\tLoss_D: 1.1898\tLoss_G: 1.1997\tD(x): 0.6343\tD(G(z)): 0.4471 / 0.2933\n",
            "[28/100][0/391]\tLoss_D: 1.1422\tLoss_G: 1.1292\tD(x): 0.6204\tD(G(z)): 0.4022 / 0.3160\n",
            "[28/100][50/391]\tLoss_D: 1.2517\tLoss_G: 0.8244\tD(x): 0.4745\tD(G(z)): 0.3171 / 0.4434\n",
            "[28/100][100/391]\tLoss_D: 1.0783\tLoss_G: 0.7786\tD(x): 0.5348\tD(G(z)): 0.2355 / 0.4701\n",
            "[28/100][150/391]\tLoss_D: 0.9764\tLoss_G: 1.3045\tD(x): 0.6727\tD(G(z)): 0.3283 / 0.2581\n",
            "[28/100][200/391]\tLoss_D: 0.9519\tLoss_G: 1.9412\tD(x): 0.7496\tD(G(z)): 0.3646 / 0.1331\n",
            "[28/100][250/391]\tLoss_D: 0.9654\tLoss_G: 1.2222\tD(x): 0.6536\tD(G(z)): 0.2897 / 0.2863\n",
            "[28/100][300/391]\tLoss_D: 1.1472\tLoss_G: 1.4723\tD(x): 0.7048\tD(G(z)): 0.4748 / 0.2194\n",
            "[28/100][350/391]\tLoss_D: 1.1600\tLoss_G: 1.1598\tD(x): 0.5234\tD(G(z)): 0.2991 / 0.3056\n",
            "[29/100][0/391]\tLoss_D: 1.1891\tLoss_G: 1.5641\tD(x): 0.7746\tD(G(z)): 0.5354 / 0.1986\n",
            "[29/100][50/391]\tLoss_D: 1.0123\tLoss_G: 1.3166\tD(x): 0.6816\tD(G(z)): 0.3673 / 0.2553\n",
            "[29/100][100/391]\tLoss_D: 1.0811\tLoss_G: 0.8854\tD(x): 0.5241\tD(G(z)): 0.2165 / 0.4158\n",
            "[29/100][150/391]\tLoss_D: 1.2939\tLoss_G: 1.7255\tD(x): 0.7091\tD(G(z)): 0.5564 / 0.1649\n",
            "[29/100][200/391]\tLoss_D: 1.0808\tLoss_G: 1.1785\tD(x): 0.6905\tD(G(z)): 0.4240 / 0.2969\n",
            "[29/100][250/391]\tLoss_D: 1.2575\tLoss_G: 0.8462\tD(x): 0.4374\tD(G(z)): 0.2459 / 0.4412\n",
            "[29/100][300/391]\tLoss_D: 1.2540\tLoss_G: 0.8280\tD(x): 0.4764\tD(G(z)): 0.3046 / 0.4442\n",
            "[29/100][350/391]\tLoss_D: 1.0509\tLoss_G: 1.7021\tD(x): 0.7872\tD(G(z)): 0.4564 / 0.1694\n",
            "[30/100][0/391]\tLoss_D: 1.2463\tLoss_G: 1.9953\tD(x): 0.7574\tD(G(z)): 0.5499 / 0.1292\n",
            "[30/100][50/391]\tLoss_D: 1.6682\tLoss_G: 0.3461\tD(x): 0.2765\tD(G(z)): 0.1345 / 0.8653\n",
            "[30/100][100/391]\tLoss_D: 1.1474\tLoss_G: 1.7034\tD(x): 0.7561\tD(G(z)): 0.5049 / 0.1694\n",
            "[30/100][150/391]\tLoss_D: 1.1396\tLoss_G: 1.4390\tD(x): 0.7423\tD(G(z)): 0.4911 / 0.2247\n",
            "[30/100][200/391]\tLoss_D: 1.0657\tLoss_G: 0.8738\tD(x): 0.5360\tD(G(z)): 0.2189 / 0.4215\n",
            "[30/100][250/391]\tLoss_D: 1.0969\tLoss_G: 1.3047\tD(x): 0.6114\tD(G(z)): 0.3502 / 0.2640\n",
            "[30/100][300/391]\tLoss_D: 1.0439\tLoss_G: 1.2152\tD(x): 0.6333\tD(G(z)): 0.3347 / 0.2872\n",
            "[30/100][350/391]\tLoss_D: 1.0342\tLoss_G: 1.2797\tD(x): 0.6979\tD(G(z)): 0.3924 / 0.2690\n",
            "[31/100][0/391]\tLoss_D: 1.0630\tLoss_G: 1.1896\tD(x): 0.6604\tD(G(z)): 0.3824 / 0.2937\n",
            "[31/100][50/391]\tLoss_D: 1.3253\tLoss_G: 1.4299\tD(x): 0.7558\tD(G(z)): 0.5823 / 0.2298\n",
            "[31/100][100/391]\tLoss_D: 1.0733\tLoss_G: 1.1741\tD(x): 0.6455\tD(G(z)): 0.3711 / 0.3057\n",
            "[31/100][150/391]\tLoss_D: 1.0403\tLoss_G: 1.4425\tD(x): 0.7334\tD(G(z)): 0.4269 / 0.2227\n",
            "[31/100][200/391]\tLoss_D: 1.5689\tLoss_G: 2.0057\tD(x): 0.8158\tD(G(z)): 0.6950 / 0.1265\n",
            "[31/100][250/391]\tLoss_D: 1.0820\tLoss_G: 1.0686\tD(x): 0.5403\tD(G(z)): 0.2552 / 0.3377\n",
            "[31/100][300/391]\tLoss_D: 1.1355\tLoss_G: 0.8975\tD(x): 0.5189\tD(G(z)): 0.2719 / 0.4116\n",
            "[31/100][350/391]\tLoss_D: 0.9881\tLoss_G: 1.5718\tD(x): 0.7326\tD(G(z)): 0.3868 / 0.1933\n",
            "[32/100][0/391]\tLoss_D: 1.0195\tLoss_G: 1.1366\tD(x): 0.6272\tD(G(z)): 0.3097 / 0.3122\n",
            "[32/100][50/391]\tLoss_D: 1.0934\tLoss_G: 0.8416\tD(x): 0.5474\tD(G(z)): 0.2722 / 0.4391\n",
            "[32/100][100/391]\tLoss_D: 1.0407\tLoss_G: 1.1692\tD(x): 0.5793\tD(G(z)): 0.2624 / 0.3078\n",
            "[32/100][150/391]\tLoss_D: 1.6497\tLoss_G: 2.6216\tD(x): 0.9022\tD(G(z)): 0.7326 / 0.0661\n",
            "[32/100][200/391]\tLoss_D: 1.1186\tLoss_G: 1.3664\tD(x): 0.7175\tD(G(z)): 0.4510 / 0.2496\n",
            "[32/100][250/391]\tLoss_D: 1.0517\tLoss_G: 1.1632\tD(x): 0.6406\tD(G(z)): 0.3577 / 0.3017\n",
            "[32/100][300/391]\tLoss_D: 1.0464\tLoss_G: 1.2769\tD(x): 0.6353\tD(G(z)): 0.3406 / 0.2701\n",
            "[32/100][350/391]\tLoss_D: 1.1207\tLoss_G: 1.4633\tD(x): 0.6531\tD(G(z)): 0.4217 / 0.2211\n",
            "[33/100][0/391]\tLoss_D: 1.2077\tLoss_G: 0.9170\tD(x): 0.4418\tD(G(z)): 0.1871 / 0.4048\n",
            "[33/100][50/391]\tLoss_D: 1.0754\tLoss_G: 0.9315\tD(x): 0.5884\tD(G(z)): 0.3169 / 0.3932\n",
            "[33/100][100/391]\tLoss_D: 1.0860\tLoss_G: 1.0163\tD(x): 0.5457\tD(G(z)): 0.2595 / 0.3540\n",
            "[33/100][150/391]\tLoss_D: 1.1268\tLoss_G: 1.0271\tD(x): 0.5799\tD(G(z)): 0.3410 / 0.3587\n",
            "[33/100][200/391]\tLoss_D: 1.1386\tLoss_G: 1.3974\tD(x): 0.6976\tD(G(z)): 0.4567 / 0.2354\n",
            "[33/100][250/391]\tLoss_D: 1.0401\tLoss_G: 1.1678\tD(x): 0.5689\tD(G(z)): 0.2544 / 0.3039\n",
            "[33/100][300/391]\tLoss_D: 1.3163\tLoss_G: 1.1877\tD(x): 0.5959\tD(G(z)): 0.4931 / 0.2996\n",
            "[33/100][350/391]\tLoss_D: 1.0703\tLoss_G: 1.1691\tD(x): 0.5964\tD(G(z)): 0.3236 / 0.3029\n",
            "[34/100][0/391]\tLoss_D: 1.0519\tLoss_G: 1.6129\tD(x): 0.7496\tD(G(z)): 0.4354 / 0.1889\n",
            "[34/100][50/391]\tLoss_D: 1.0258\tLoss_G: 1.0742\tD(x): 0.5832\tD(G(z)): 0.2572 / 0.3411\n",
            "[34/100][100/391]\tLoss_D: 1.0329\tLoss_G: 1.2826\tD(x): 0.6960\tD(G(z)): 0.3868 / 0.2650\n",
            "[34/100][150/391]\tLoss_D: 1.0448\tLoss_G: 1.1253\tD(x): 0.5917\tD(G(z)): 0.2882 / 0.3227\n",
            "[34/100][200/391]\tLoss_D: 1.1755\tLoss_G: 0.8483\tD(x): 0.4814\tD(G(z)): 0.2390 / 0.4353\n",
            "[34/100][250/391]\tLoss_D: 1.0451\tLoss_G: 1.2079\tD(x): 0.5737\tD(G(z)): 0.2455 / 0.2927\n",
            "[34/100][300/391]\tLoss_D: 1.0924\tLoss_G: 1.1525\tD(x): 0.6160\tD(G(z)): 0.3449 / 0.3124\n",
            "[34/100][350/391]\tLoss_D: 1.1070\tLoss_G: 1.0856\tD(x): 0.5555\tD(G(z)): 0.2852 / 0.3365\n",
            "[35/100][0/391]\tLoss_D: 1.1934\tLoss_G: 1.8184\tD(x): 0.8522\tD(G(z)): 0.5513 / 0.1540\n",
            "[35/100][50/391]\tLoss_D: 1.0653\tLoss_G: 1.1019\tD(x): 0.6756\tD(G(z)): 0.3971 / 0.3265\n",
            "[35/100][100/391]\tLoss_D: 0.9516\tLoss_G: 1.3763\tD(x): 0.6901\tD(G(z)): 0.3086 / 0.2463\n",
            "[35/100][150/391]\tLoss_D: 1.0578\tLoss_G: 1.0743\tD(x): 0.5790\tD(G(z)): 0.2756 / 0.3368\n",
            "[35/100][200/391]\tLoss_D: 0.9600\tLoss_G: 1.4474\tD(x): 0.7022\tD(G(z)): 0.3360 / 0.2224\n",
            "[35/100][250/391]\tLoss_D: 1.0769\tLoss_G: 1.3463\tD(x): 0.6551\tD(G(z)): 0.3777 / 0.2541\n",
            "[35/100][300/391]\tLoss_D: 1.0324\tLoss_G: 1.1745\tD(x): 0.6401\tD(G(z)): 0.3350 / 0.2996\n",
            "[35/100][350/391]\tLoss_D: 1.0303\tLoss_G: 1.2993\tD(x): 0.6644\tD(G(z)): 0.3588 / 0.2640\n",
            "[36/100][0/391]\tLoss_D: 0.9269\tLoss_G: 1.3523\tD(x): 0.7367\tD(G(z)): 0.3208 / 0.2543\n",
            "[36/100][50/391]\tLoss_D: 1.0783\tLoss_G: 0.9467\tD(x): 0.5237\tD(G(z)): 0.2129 / 0.3971\n",
            "[36/100][100/391]\tLoss_D: 0.9797\tLoss_G: 1.2011\tD(x): 0.6496\tD(G(z)): 0.2994 / 0.2928\n",
            "[36/100][150/391]\tLoss_D: 0.9607\tLoss_G: 1.5416\tD(x): 0.6690\tD(G(z)): 0.3036 / 0.2019\n",
            "[36/100][200/391]\tLoss_D: 1.2260\tLoss_G: 1.6052\tD(x): 0.7290\tD(G(z)): 0.5274 / 0.1923\n",
            "[36/100][250/391]\tLoss_D: 1.0101\tLoss_G: 1.4644\tD(x): 0.7569\tD(G(z)): 0.4034 / 0.2240\n",
            "[36/100][300/391]\tLoss_D: 1.0860\tLoss_G: 1.3858\tD(x): 0.6742\tD(G(z)): 0.4073 / 0.2418\n",
            "[36/100][350/391]\tLoss_D: 1.1067\tLoss_G: 1.5004\tD(x): 0.6851\tD(G(z)): 0.4330 / 0.2150\n",
            "[37/100][0/391]\tLoss_D: 1.1618\tLoss_G: 0.9369\tD(x): 0.4848\tD(G(z)): 0.2275 / 0.3953\n",
            "[37/100][50/391]\tLoss_D: 1.0123\tLoss_G: 1.7239\tD(x): 0.7741\tD(G(z)): 0.4185 / 0.1675\n",
            "[37/100][100/391]\tLoss_D: 1.1188\tLoss_G: 1.2377\tD(x): 0.5602\tD(G(z)): 0.3050 / 0.2884\n",
            "[37/100][150/391]\tLoss_D: 1.0205\tLoss_G: 1.3551\tD(x): 0.6849\tD(G(z)): 0.3586 / 0.2566\n",
            "[37/100][200/391]\tLoss_D: 1.0208\tLoss_G: 1.0353\tD(x): 0.5718\tD(G(z)): 0.2147 / 0.3559\n",
            "[37/100][250/391]\tLoss_D: 1.1847\tLoss_G: 1.3506\tD(x): 0.6269\tD(G(z)): 0.4391 / 0.2525\n",
            "[37/100][300/391]\tLoss_D: 1.0788\tLoss_G: 1.3158\tD(x): 0.6632\tD(G(z)): 0.3980 / 0.2575\n",
            "[37/100][350/391]\tLoss_D: 1.5537\tLoss_G: 0.6474\tD(x): 0.3132\tD(G(z)): 0.1599 / 0.5528\n",
            "[38/100][0/391]\tLoss_D: 1.3567\tLoss_G: 2.1653\tD(x): 0.8328\tD(G(z)): 0.6192 / 0.1086\n",
            "[38/100][50/391]\tLoss_D: 1.0279\tLoss_G: 0.8220\tD(x): 0.5635\tD(G(z)): 0.2178 / 0.4529\n",
            "[38/100][100/391]\tLoss_D: 1.0733\tLoss_G: 1.6135\tD(x): 0.7181\tD(G(z)): 0.4340 / 0.1902\n",
            "[38/100][150/391]\tLoss_D: 1.0094\tLoss_G: 1.1906\tD(x): 0.6363\tD(G(z)): 0.3057 / 0.2999\n",
            "[38/100][200/391]\tLoss_D: 1.0633\tLoss_G: 1.1139\tD(x): 0.6005\tD(G(z)): 0.3167 / 0.3277\n",
            "[38/100][250/391]\tLoss_D: 0.8822\tLoss_G: 1.7736\tD(x): 0.7726\tD(G(z)): 0.3213 / 0.1597\n",
            "[38/100][300/391]\tLoss_D: 1.0155\tLoss_G: 1.5897\tD(x): 0.7483\tD(G(z)): 0.4105 / 0.1961\n",
            "[38/100][350/391]\tLoss_D: 1.1549\tLoss_G: 1.6224\tD(x): 0.6960\tD(G(z)): 0.4569 / 0.1885\n",
            "[39/100][0/391]\tLoss_D: 1.0992\tLoss_G: 1.2102\tD(x): 0.6608\tD(G(z)): 0.4031 / 0.2943\n",
            "[39/100][50/391]\tLoss_D: 0.9317\tLoss_G: 1.5013\tD(x): 0.7253\tD(G(z)): 0.3288 / 0.2123\n",
            "[39/100][100/391]\tLoss_D: 1.1357\tLoss_G: 1.4526\tD(x): 0.7293\tD(G(z)): 0.4653 / 0.2271\n",
            "[39/100][150/391]\tLoss_D: 1.0242\tLoss_G: 1.1500\tD(x): 0.6113\tD(G(z)): 0.2762 / 0.3122\n",
            "[39/100][200/391]\tLoss_D: 1.0703\tLoss_G: 1.6289\tD(x): 0.7331\tD(G(z)): 0.4369 / 0.1881\n",
            "[39/100][250/391]\tLoss_D: 1.0374\tLoss_G: 1.3125\tD(x): 0.7300\tD(G(z)): 0.4046 / 0.2583\n",
            "[39/100][300/391]\tLoss_D: 0.9404\tLoss_G: 1.6034\tD(x): 0.7359\tD(G(z)): 0.3411 / 0.1919\n",
            "[39/100][350/391]\tLoss_D: 1.2635\tLoss_G: 0.6334\tD(x): 0.4343\tD(G(z)): 0.2322 / 0.5643\n",
            "[40/100][0/391]\tLoss_D: 0.9998\tLoss_G: 1.3354\tD(x): 0.6736\tD(G(z)): 0.3475 / 0.2502\n",
            "[40/100][50/391]\tLoss_D: 1.1996\tLoss_G: 2.2003\tD(x): 0.7973\tD(G(z)): 0.5434 / 0.1017\n",
            "[40/100][100/391]\tLoss_D: 1.1408\tLoss_G: 0.9857\tD(x): 0.5004\tD(G(z)): 0.2415 / 0.3765\n",
            "[40/100][150/391]\tLoss_D: 1.0432\tLoss_G: 1.3053\tD(x): 0.6562\tD(G(z)): 0.3593 / 0.2626\n",
            "[40/100][200/391]\tLoss_D: 1.1062\tLoss_G: 1.4296\tD(x): 0.7200\tD(G(z)): 0.4514 / 0.2333\n",
            "[40/100][250/391]\tLoss_D: 1.1451\tLoss_G: 1.7791\tD(x): 0.8173\tD(G(z)): 0.5170 / 0.1602\n",
            "[40/100][300/391]\tLoss_D: 1.0536\tLoss_G: 2.0192\tD(x): 0.7736\tD(G(z)): 0.4459 / 0.1227\n",
            "[40/100][350/391]\tLoss_D: 1.4875\tLoss_G: 0.5978\tD(x): 0.3276\tD(G(z)): 0.1481 / 0.5900\n",
            "[41/100][0/391]\tLoss_D: 1.0502\tLoss_G: 1.0353\tD(x): 0.5888\tD(G(z)): 0.2912 / 0.3591\n",
            "[41/100][50/391]\tLoss_D: 0.9509\tLoss_G: 1.5913\tD(x): 0.7894\tD(G(z)): 0.3812 / 0.1950\n",
            "[41/100][100/391]\tLoss_D: 1.0352\tLoss_G: 1.4124\tD(x): 0.6490\tD(G(z)): 0.3441 / 0.2372\n",
            "[41/100][150/391]\tLoss_D: 0.9978\tLoss_G: 1.1067\tD(x): 0.6097\tD(G(z)): 0.2598 / 0.3322\n",
            "[41/100][200/391]\tLoss_D: 1.0900\tLoss_G: 1.1062\tD(x): 0.5231\tD(G(z)): 0.2022 / 0.3270\n",
            "[41/100][250/391]\tLoss_D: 0.9917\tLoss_G: 1.5864\tD(x): 0.7377\tD(G(z)): 0.3809 / 0.1960\n",
            "[41/100][300/391]\tLoss_D: 1.0391\tLoss_G: 1.1053\tD(x): 0.6045\tD(G(z)): 0.2922 / 0.3327\n",
            "[41/100][350/391]\tLoss_D: 0.9949\tLoss_G: 1.2226\tD(x): 0.6197\tD(G(z)): 0.2788 / 0.2830\n",
            "[42/100][0/391]\tLoss_D: 0.9948\tLoss_G: 1.4951\tD(x): 0.6707\tD(G(z)): 0.3327 / 0.2155\n",
            "[42/100][50/391]\tLoss_D: 0.9023\tLoss_G: 1.3587\tD(x): 0.7125\tD(G(z)): 0.2834 / 0.2448\n",
            "[42/100][100/391]\tLoss_D: 0.9790\tLoss_G: 1.0587\tD(x): 0.5923\tD(G(z)): 0.2109 / 0.3459\n",
            "[42/100][150/391]\tLoss_D: 0.9263\tLoss_G: 1.4489\tD(x): 0.7254\tD(G(z)): 0.3190 / 0.2228\n",
            "[42/100][200/391]\tLoss_D: 0.9847\tLoss_G: 1.4082\tD(x): 0.7112\tD(G(z)): 0.3484 / 0.2392\n",
            "[42/100][250/391]\tLoss_D: 1.0204\tLoss_G: 1.2314\tD(x): 0.6272\tD(G(z)): 0.3024 / 0.2847\n",
            "[42/100][300/391]\tLoss_D: 0.9851\tLoss_G: 0.9538\tD(x): 0.5955\tD(G(z)): 0.2187 / 0.3908\n",
            "[42/100][350/391]\tLoss_D: 0.9943\tLoss_G: 1.2920\tD(x): 0.6814\tD(G(z)): 0.3343 / 0.2685\n",
            "[43/100][0/391]\tLoss_D: 0.9160\tLoss_G: 1.4840\tD(x): 0.6905\tD(G(z)): 0.2675 / 0.2258\n",
            "[43/100][50/391]\tLoss_D: 0.9623\tLoss_G: 1.1173\tD(x): 0.6102\tD(G(z)): 0.2145 / 0.3300\n",
            "[43/100][100/391]\tLoss_D: 0.9742\tLoss_G: 1.3749\tD(x): 0.6410\tD(G(z)): 0.2706 / 0.2516\n",
            "[43/100][150/391]\tLoss_D: 1.0946\tLoss_G: 1.5598\tD(x): 0.7140\tD(G(z)): 0.4346 / 0.1987\n",
            "[43/100][200/391]\tLoss_D: 1.4692\tLoss_G: 2.4897\tD(x): 0.8604\tD(G(z)): 0.6717 / 0.0818\n",
            "[43/100][250/391]\tLoss_D: 1.0219\tLoss_G: 1.6721\tD(x): 0.7817\tD(G(z)): 0.4319 / 0.1736\n",
            "[43/100][300/391]\tLoss_D: 1.0155\tLoss_G: 2.0197\tD(x): 0.8211\tD(G(z)): 0.4357 / 0.1257\n",
            "[43/100][350/391]\tLoss_D: 1.0033\tLoss_G: 1.2650\tD(x): 0.6704\tD(G(z)): 0.3286 / 0.2834\n",
            "[44/100][0/391]\tLoss_D: 1.0665\tLoss_G: 1.3678\tD(x): 0.7266\tD(G(z)): 0.4143 / 0.2506\n",
            "[44/100][50/391]\tLoss_D: 0.9758\tLoss_G: 1.5562\tD(x): 0.7064\tD(G(z)): 0.3477 / 0.2019\n",
            "[44/100][100/391]\tLoss_D: 0.9425\tLoss_G: 1.3987\tD(x): 0.7176\tD(G(z)): 0.3349 / 0.2302\n",
            "[44/100][150/391]\tLoss_D: 0.9610\tLoss_G: 1.1277\tD(x): 0.6683\tD(G(z)): 0.2921 / 0.3230\n",
            "[44/100][200/391]\tLoss_D: 1.6595\tLoss_G: 2.6157\tD(x): 0.8652\tD(G(z)): 0.7265 / 0.0677\n",
            "[44/100][250/391]\tLoss_D: 1.0291\tLoss_G: 1.1833\tD(x): 0.6597\tD(G(z)): 0.3525 / 0.3014\n",
            "[44/100][300/391]\tLoss_D: 0.9475\tLoss_G: 1.0776\tD(x): 0.6490\tD(G(z)): 0.2657 / 0.3367\n",
            "[44/100][350/391]\tLoss_D: 1.0508\tLoss_G: 1.3641\tD(x): 0.6509\tD(G(z)): 0.3611 / 0.2474\n",
            "[45/100][0/391]\tLoss_D: 0.9202\tLoss_G: 1.4345\tD(x): 0.6767\tD(G(z)): 0.2657 / 0.2340\n",
            "[45/100][50/391]\tLoss_D: 0.9802\tLoss_G: 1.4458\tD(x): 0.7379\tD(G(z)): 0.3733 / 0.2260\n",
            "[45/100][100/391]\tLoss_D: 1.0237\tLoss_G: 1.3960\tD(x): 0.6854\tD(G(z)): 0.3662 / 0.2384\n",
            "[45/100][150/391]\tLoss_D: 0.9286\tLoss_G: 1.6000\tD(x): 0.7181\tD(G(z)): 0.3162 / 0.1922\n",
            "[45/100][200/391]\tLoss_D: 0.9128\tLoss_G: 1.1716\tD(x): 0.6472\tD(G(z)): 0.2012 / 0.3055\n",
            "[45/100][250/391]\tLoss_D: 0.9684\tLoss_G: 1.4570\tD(x): 0.7076\tD(G(z)): 0.3341 / 0.2246\n",
            "[45/100][300/391]\tLoss_D: 1.0920\tLoss_G: 1.8106\tD(x): 0.7935\tD(G(z)): 0.4649 / 0.1601\n",
            "[45/100][350/391]\tLoss_D: 0.9794\tLoss_G: 1.1783\tD(x): 0.5975\tD(G(z)): 0.1921 / 0.3042\n",
            "[46/100][0/391]\tLoss_D: 1.1598\tLoss_G: 1.9607\tD(x): 0.7952\tD(G(z)): 0.5181 / 0.1332\n",
            "[46/100][50/391]\tLoss_D: 0.9780\tLoss_G: 1.1751\tD(x): 0.6396\tD(G(z)): 0.2703 / 0.3026\n",
            "[46/100][100/391]\tLoss_D: 1.0802\tLoss_G: 1.1219\tD(x): 0.5111\tD(G(z)): 0.1433 / 0.3317\n",
            "[46/100][150/391]\tLoss_D: 0.9924\tLoss_G: 1.1937\tD(x): 0.6388\tD(G(z)): 0.2821 / 0.2960\n",
            "[46/100][200/391]\tLoss_D: 2.1348\tLoss_G: 1.5876\tD(x): 0.8603\tD(G(z)): 0.7968 / 0.2175\n",
            "[46/100][250/391]\tLoss_D: 1.0339\tLoss_G: 1.1993\tD(x): 0.6153\tD(G(z)): 0.3067 / 0.2961\n",
            "[46/100][300/391]\tLoss_D: 0.9834\tLoss_G: 1.3864\tD(x): 0.6915\tD(G(z)): 0.3357 / 0.2445\n",
            "[46/100][350/391]\tLoss_D: 0.9491\tLoss_G: 1.5088\tD(x): 0.7126\tD(G(z)): 0.3292 / 0.2069\n",
            "[47/100][0/391]\tLoss_D: 1.1865\tLoss_G: 2.0117\tD(x): 0.8474\tD(G(z)): 0.5417 / 0.1231\n",
            "[47/100][50/391]\tLoss_D: 0.9586\tLoss_G: 1.6905\tD(x): 0.7714\tD(G(z)): 0.3682 / 0.1794\n",
            "[47/100][100/391]\tLoss_D: 1.4037\tLoss_G: 0.5191\tD(x): 0.3575\tD(G(z)): 0.1131 / 0.6610\n",
            "[47/100][150/391]\tLoss_D: 1.0514\tLoss_G: 0.8749\tD(x): 0.5670\tD(G(z)): 0.2520 / 0.4275\n",
            "[47/100][200/391]\tLoss_D: 0.9140\tLoss_G: 1.3020\tD(x): 0.6467\tD(G(z)): 0.1988 / 0.2649\n",
            "[47/100][250/391]\tLoss_D: 1.1795\tLoss_G: 0.9591\tD(x): 0.4652\tD(G(z)): 0.1720 / 0.3935\n",
            "[47/100][300/391]\tLoss_D: 1.0658\tLoss_G: 0.8856\tD(x): 0.5669\tD(G(z)): 0.2582 / 0.4157\n",
            "[47/100][350/391]\tLoss_D: 1.0059\tLoss_G: 1.7485\tD(x): 0.7458\tD(G(z)): 0.3844 / 0.1697\n",
            "[48/100][0/391]\tLoss_D: 1.1784\tLoss_G: 1.7526\tD(x): 0.7997\tD(G(z)): 0.5212 / 0.1640\n",
            "[48/100][50/391]\tLoss_D: 0.9545\tLoss_G: 1.1542\tD(x): 0.6241\tD(G(z)): 0.2267 / 0.3145\n",
            "[48/100][100/391]\tLoss_D: 0.9094\tLoss_G: 1.4758\tD(x): 0.7544\tD(G(z)): 0.3239 / 0.2232\n",
            "[48/100][150/391]\tLoss_D: 0.9795\tLoss_G: 1.1150\tD(x): 0.6395\tD(G(z)): 0.2898 / 0.3209\n",
            "[48/100][200/391]\tLoss_D: 1.2517\tLoss_G: 0.7612\tD(x): 0.4371\tD(G(z)): 0.2008 / 0.4913\n",
            "[48/100][250/391]\tLoss_D: 0.9322\tLoss_G: 1.2244\tD(x): 0.6217\tD(G(z)): 0.1890 / 0.2898\n",
            "[48/100][300/391]\tLoss_D: 1.0153\tLoss_G: 1.2132\tD(x): 0.6731\tD(G(z)): 0.3511 / 0.2950\n",
            "[48/100][350/391]\tLoss_D: 1.1431\tLoss_G: 1.7571\tD(x): 0.7555\tD(G(z)): 0.4835 / 0.1676\n",
            "[49/100][0/391]\tLoss_D: 1.0487\tLoss_G: 0.9879\tD(x): 0.5613\tD(G(z)): 0.2156 / 0.3792\n",
            "[49/100][50/391]\tLoss_D: 0.9349\tLoss_G: 1.3500\tD(x): 0.6940\tD(G(z)): 0.2963 / 0.2558\n",
            "[49/100][100/391]\tLoss_D: 1.1425\tLoss_G: 2.3765\tD(x): 0.8727\tD(G(z)): 0.5342 / 0.0882\n",
            "[49/100][150/391]\tLoss_D: 1.2837\tLoss_G: 1.5798\tD(x): 0.7184\tD(G(z)): 0.5371 / 0.2034\n",
            "[49/100][200/391]\tLoss_D: 1.0990\tLoss_G: 1.4282\tD(x): 0.7098\tD(G(z)): 0.4350 / 0.2328\n",
            "[49/100][250/391]\tLoss_D: 1.0631\tLoss_G: 1.1925\tD(x): 0.5884\tD(G(z)): 0.2916 / 0.3005\n",
            "[49/100][300/391]\tLoss_D: 1.0299\tLoss_G: 1.4487\tD(x): 0.6238\tD(G(z)): 0.3039 / 0.2276\n",
            "[49/100][350/391]\tLoss_D: 1.0890\tLoss_G: 0.9932\tD(x): 0.5252\tD(G(z)): 0.1953 / 0.3801\n",
            "[50/100][0/391]\tLoss_D: 1.0628\tLoss_G: 1.8953\tD(x): 0.7822\tD(G(z)): 0.4520 / 0.1391\n",
            "[50/100][50/391]\tLoss_D: 0.9687\tLoss_G: 1.5922\tD(x): 0.7169\tD(G(z)): 0.3482 / 0.1941\n",
            "[50/100][100/391]\tLoss_D: 1.6145\tLoss_G: 0.3813\tD(x): 0.2857\tD(G(z)): 0.0987 / 0.8040\n",
            "[50/100][150/391]\tLoss_D: 0.9707\tLoss_G: 1.3606\tD(x): 0.7396\tD(G(z)): 0.3535 / 0.2510\n",
            "[50/100][200/391]\tLoss_D: 0.9368\tLoss_G: 1.3667\tD(x): 0.6886\tD(G(z)): 0.2914 / 0.2539\n",
            "[50/100][250/391]\tLoss_D: 1.2274\tLoss_G: 2.1518\tD(x): 0.8111\tD(G(z)): 0.5590 / 0.1062\n",
            "[50/100][300/391]\tLoss_D: 1.2161\tLoss_G: 0.8754\tD(x): 0.4352\tD(G(z)): 0.1386 / 0.4271\n",
            "[50/100][350/391]\tLoss_D: 0.9252\tLoss_G: 1.4443\tD(x): 0.7137\tD(G(z)): 0.3010 / 0.2272\n",
            "[51/100][0/391]\tLoss_D: 1.4020\tLoss_G: 1.1554\tD(x): 0.4398\tD(G(z)): 0.3107 / 0.3311\n",
            "[51/100][50/391]\tLoss_D: 0.9383\tLoss_G: 1.3251\tD(x): 0.6757\tD(G(z)): 0.2755 / 0.2591\n",
            "[51/100][100/391]\tLoss_D: 1.0662\tLoss_G: 1.0312\tD(x): 0.5741\tD(G(z)): 0.2804 / 0.3623\n",
            "[51/100][150/391]\tLoss_D: 0.9094\tLoss_G: 1.2416\tD(x): 0.6533\tD(G(z)): 0.2062 / 0.2820\n",
            "[51/100][200/391]\tLoss_D: 0.9356\tLoss_G: 1.7044\tD(x): 0.7576\tD(G(z)): 0.3418 / 0.1707\n",
            "[51/100][250/391]\tLoss_D: 0.9310\tLoss_G: 1.3444\tD(x): 0.6849\tD(G(z)): 0.2875 / 0.2514\n",
            "[51/100][300/391]\tLoss_D: 1.0513\tLoss_G: 1.7132\tD(x): 0.7586\tD(G(z)): 0.4326 / 0.1744\n",
            "[51/100][350/391]\tLoss_D: 0.9646\tLoss_G: 1.3965\tD(x): 0.7042\tD(G(z)): 0.3242 / 0.2463\n",
            "[52/100][0/391]\tLoss_D: 1.1620\tLoss_G: 1.9815\tD(x): 0.8267\tD(G(z)): 0.5245 / 0.1323\n",
            "[52/100][50/391]\tLoss_D: 0.9167\tLoss_G: 1.7694\tD(x): 0.7591\tD(G(z)): 0.3277 / 0.1620\n",
            "[52/100][100/391]\tLoss_D: 1.0740\tLoss_G: 1.0846\tD(x): 0.5359\tD(G(z)): 0.2108 / 0.3418\n",
            "[52/100][150/391]\tLoss_D: 0.9516\tLoss_G: 1.7426\tD(x): 0.7583\tD(G(z)): 0.3600 / 0.1669\n",
            "[52/100][200/391]\tLoss_D: 0.8749\tLoss_G: 1.4085\tD(x): 0.7028\tD(G(z)): 0.2378 / 0.2392\n",
            "[52/100][250/391]\tLoss_D: 2.5662\tLoss_G: 0.3905\tD(x): 0.1214\tD(G(z)): 0.0610 / 0.8184\n",
            "[52/100][300/391]\tLoss_D: 0.9526\tLoss_G: 1.3317\tD(x): 0.7049\tD(G(z)): 0.3239 / 0.2594\n",
            "[52/100][350/391]\tLoss_D: 0.9187\tLoss_G: 1.5674\tD(x): 0.7269\tD(G(z)): 0.3017 / 0.1977\n",
            "[53/100][0/391]\tLoss_D: 1.0153\tLoss_G: 1.6213\tD(x): 0.7587\tD(G(z)): 0.4100 / 0.1951\n",
            "[53/100][50/391]\tLoss_D: 0.9787\tLoss_G: 1.1920\tD(x): 0.6843\tD(G(z)): 0.3087 / 0.3062\n",
            "[53/100][100/391]\tLoss_D: 0.8722\tLoss_G: 1.4678\tD(x): 0.6925\tD(G(z)): 0.2257 / 0.2227\n",
            "[53/100][150/391]\tLoss_D: 1.0116\tLoss_G: 1.1231\tD(x): 0.6674\tD(G(z)): 0.3275 / 0.3297\n",
            "[53/100][200/391]\tLoss_D: 0.9449\tLoss_G: 1.7499\tD(x): 0.7427\tD(G(z)): 0.3466 / 0.1617\n",
            "[53/100][250/391]\tLoss_D: 0.8582\tLoss_G: 1.5940\tD(x): 0.7255\tD(G(z)): 0.2470 / 0.1919\n",
            "[53/100][300/391]\tLoss_D: 0.9322\tLoss_G: 1.2928\tD(x): 0.6993\tD(G(z)): 0.3042 / 0.2644\n",
            "[53/100][350/391]\tLoss_D: 1.1103\tLoss_G: 1.9005\tD(x): 0.7678\tD(G(z)): 0.4616 / 0.1483\n",
            "[54/100][0/391]\tLoss_D: 0.8597\tLoss_G: 1.7036\tD(x): 0.7523\tD(G(z)): 0.2667 / 0.1751\n",
            "[54/100][50/391]\tLoss_D: 0.9222\tLoss_G: 1.3325\tD(x): 0.6633\tD(G(z)): 0.2473 / 0.2566\n",
            "[54/100][100/391]\tLoss_D: 0.9396\tLoss_G: 1.2816\tD(x): 0.6129\tD(G(z)): 0.1586 / 0.2758\n",
            "[54/100][150/391]\tLoss_D: 0.9154\tLoss_G: 1.2930\tD(x): 0.6958\tD(G(z)): 0.2664 / 0.2741\n",
            "[54/100][200/391]\tLoss_D: 1.1320\tLoss_G: 2.0654\tD(x): 0.7958\tD(G(z)): 0.4943 / 0.1191\n",
            "[54/100][250/391]\tLoss_D: 1.1087\tLoss_G: 0.9155\tD(x): 0.4949\tD(G(z)): 0.1607 / 0.4169\n",
            "[54/100][300/391]\tLoss_D: 0.9395\tLoss_G: 1.2381\tD(x): 0.6340\tD(G(z)): 0.2305 / 0.2841\n",
            "[54/100][350/391]\tLoss_D: 1.1652\tLoss_G: 1.2204\tD(x): 0.6522\tD(G(z)): 0.4367 / 0.2888\n",
            "[55/100][0/391]\tLoss_D: 0.9477\tLoss_G: 1.2366\tD(x): 0.6121\tD(G(z)): 0.1727 / 0.2920\n",
            "[55/100][50/391]\tLoss_D: 0.9457\tLoss_G: 1.4857\tD(x): 0.7222\tD(G(z)): 0.3205 / 0.2212\n",
            "[55/100][100/391]\tLoss_D: 0.9371\tLoss_G: 1.3613\tD(x): 0.7313\tD(G(z)): 0.3310 / 0.2438\n",
            "[55/100][150/391]\tLoss_D: 0.9598\tLoss_G: 1.1417\tD(x): 0.6106\tD(G(z)): 0.1971 / 0.3181\n",
            "[55/100][200/391]\tLoss_D: 0.9856\tLoss_G: 1.9610\tD(x): 0.7560\tD(G(z)): 0.3898 / 0.1289\n",
            "[55/100][250/391]\tLoss_D: 0.8954\tLoss_G: 1.7033\tD(x): 0.7443\tD(G(z)): 0.3044 / 0.1701\n",
            "[55/100][300/391]\tLoss_D: 0.9983\tLoss_G: 1.1154\tD(x): 0.6262\tD(G(z)): 0.2701 / 0.3321\n",
            "[55/100][350/391]\tLoss_D: 1.0838\tLoss_G: 1.9136\tD(x): 0.8176\tD(G(z)): 0.4630 / 0.1485\n",
            "[56/100][0/391]\tLoss_D: 1.0180\tLoss_G: 1.8401\tD(x): 0.7893\tD(G(z)): 0.4264 / 0.1550\n",
            "[56/100][50/391]\tLoss_D: 0.9611\tLoss_G: 1.2519\tD(x): 0.6356\tD(G(z)): 0.2370 / 0.2882\n",
            "[56/100][100/391]\tLoss_D: 1.0209\tLoss_G: 1.5429\tD(x): 0.6768\tD(G(z)): 0.3452 / 0.2062\n",
            "[56/100][150/391]\tLoss_D: 0.8939\tLoss_G: 1.5636\tD(x): 0.8197\tD(G(z)): 0.3398 / 0.2021\n",
            "[56/100][200/391]\tLoss_D: 0.9993\tLoss_G: 2.2241\tD(x): 0.8171\tD(G(z)): 0.4175 / 0.1019\n",
            "[56/100][250/391]\tLoss_D: 0.9398\tLoss_G: 1.3697\tD(x): 0.7364\tD(G(z)): 0.3296 / 0.2447\n",
            "[56/100][300/391]\tLoss_D: 1.1129\tLoss_G: 1.4135\tD(x): 0.6646\tD(G(z)): 0.4041 / 0.2444\n",
            "[56/100][350/391]\tLoss_D: 0.9860\tLoss_G: 1.1663\tD(x): 0.6164\tD(G(z)): 0.2515 / 0.3120\n",
            "[57/100][0/391]\tLoss_D: 0.9037\tLoss_G: 1.4179\tD(x): 0.6879\tD(G(z)): 0.2573 / 0.2364\n",
            "[57/100][50/391]\tLoss_D: 1.1513\tLoss_G: 1.5558\tD(x): 0.6984\tD(G(z)): 0.4534 / 0.2226\n",
            "[57/100][100/391]\tLoss_D: 1.2171\tLoss_G: 2.2577\tD(x): 0.8204\tD(G(z)): 0.5449 / 0.0992\n",
            "[57/100][150/391]\tLoss_D: 0.9066\tLoss_G: 1.4347\tD(x): 0.7569\tD(G(z)): 0.3219 / 0.2323\n",
            "[57/100][200/391]\tLoss_D: 1.1193\tLoss_G: 1.9635\tD(x): 0.8381\tD(G(z)): 0.5042 / 0.1376\n",
            "[57/100][250/391]\tLoss_D: 1.1364\tLoss_G: 0.8661\tD(x): 0.4991\tD(G(z)): 0.1936 / 0.4405\n",
            "[57/100][300/391]\tLoss_D: 1.0605\tLoss_G: 1.3597\tD(x): 0.7462\tD(G(z)): 0.4314 / 0.2553\n",
            "[57/100][350/391]\tLoss_D: 1.0399\tLoss_G: 1.3348\tD(x): 0.6392\tD(G(z)): 0.3236 / 0.2592\n",
            "[58/100][0/391]\tLoss_D: 1.0650\tLoss_G: 1.9034\tD(x): 0.8381\tD(G(z)): 0.4718 / 0.1439\n",
            "[58/100][50/391]\tLoss_D: 1.0230\tLoss_G: 1.0156\tD(x): 0.5685\tD(G(z)): 0.2114 / 0.3652\n",
            "[58/100][100/391]\tLoss_D: 0.9395\tLoss_G: 1.5582\tD(x): 0.7444\tD(G(z)): 0.3358 / 0.2005\n",
            "[58/100][150/391]\tLoss_D: 0.9672\tLoss_G: 1.1332\tD(x): 0.6002\tD(G(z)): 0.1824 / 0.3231\n",
            "[58/100][200/391]\tLoss_D: 0.8460\tLoss_G: 1.4350\tD(x): 0.7240\tD(G(z)): 0.2118 / 0.2375\n",
            "[58/100][250/391]\tLoss_D: 1.5970\tLoss_G: 2.1428\tD(x): 0.8760\tD(G(z)): 0.6941 / 0.1184\n",
            "[58/100][300/391]\tLoss_D: 0.9198\tLoss_G: 1.5097\tD(x): 0.7571\tD(G(z)): 0.3239 / 0.2176\n",
            "[58/100][350/391]\tLoss_D: 0.8863\tLoss_G: 1.3207\tD(x): 0.7116\tD(G(z)): 0.2628 / 0.2564\n",
            "[59/100][0/391]\tLoss_D: 0.8601\tLoss_G: 1.4852\tD(x): 0.7001\tD(G(z)): 0.2072 / 0.2315\n",
            "[59/100][50/391]\tLoss_D: 1.3086\tLoss_G: 2.4127\tD(x): 0.8918\tD(G(z)): 0.6083 / 0.0870\n",
            "[59/100][100/391]\tLoss_D: 1.0857\tLoss_G: 1.6985\tD(x): 0.7665\tD(G(z)): 0.4472 / 0.1760\n",
            "[59/100][150/391]\tLoss_D: 0.8910\tLoss_G: 1.3177\tD(x): 0.6826\tD(G(z)): 0.2298 / 0.2643\n",
            "[59/100][200/391]\tLoss_D: 0.9760\tLoss_G: 1.4886\tD(x): 0.7738\tD(G(z)): 0.3888 / 0.2167\n",
            "[59/100][250/391]\tLoss_D: 0.9080\tLoss_G: 1.4535\tD(x): 0.6903\tD(G(z)): 0.2629 / 0.2286\n",
            "[59/100][300/391]\tLoss_D: 1.0466\tLoss_G: 1.4412\tD(x): 0.7255\tD(G(z)): 0.4064 / 0.2300\n",
            "[59/100][350/391]\tLoss_D: 1.0478\tLoss_G: 1.4582\tD(x): 0.6836\tD(G(z)): 0.3778 / 0.2273\n",
            "[60/100][0/391]\tLoss_D: 0.9712\tLoss_G: 1.9239\tD(x): 0.8388\tD(G(z)): 0.4004 / 0.1416\n",
            "[60/100][50/391]\tLoss_D: 0.9259\tLoss_G: 1.1382\tD(x): 0.6503\tD(G(z)): 0.2210 / 0.3198\n",
            "[60/100][100/391]\tLoss_D: 0.9664\tLoss_G: 1.2580\tD(x): 0.7217\tD(G(z)): 0.3324 / 0.2804\n",
            "[60/100][150/391]\tLoss_D: 0.9500\tLoss_G: 1.5557\tD(x): 0.6906\tD(G(z)): 0.2911 / 0.2067\n",
            "[60/100][200/391]\tLoss_D: 1.1095\tLoss_G: 2.3543\tD(x): 0.8831\tD(G(z)): 0.5050 / 0.0879\n",
            "[60/100][250/391]\tLoss_D: 0.9876\tLoss_G: 1.7478\tD(x): 0.8413\tD(G(z)): 0.4282 / 0.1639\n",
            "[60/100][300/391]\tLoss_D: 0.9598\tLoss_G: 1.8327\tD(x): 0.8138\tD(G(z)): 0.3870 / 0.1510\n",
            "[60/100][350/391]\tLoss_D: 1.1974\tLoss_G: 1.0492\tD(x): 0.5173\tD(G(z)): 0.3073 / 0.3599\n",
            "[61/100][0/391]\tLoss_D: 1.0780\tLoss_G: 1.0698\tD(x): 0.5439\tD(G(z)): 0.2212 / 0.3447\n",
            "[61/100][50/391]\tLoss_D: 0.9111\tLoss_G: 1.5933\tD(x): 0.7583\tD(G(z)): 0.3159 / 0.1988\n",
            "[61/100][100/391]\tLoss_D: 0.8781\tLoss_G: 1.3654\tD(x): 0.6847\tD(G(z)): 0.2220 / 0.2496\n",
            "[61/100][150/391]\tLoss_D: 0.8653\tLoss_G: 1.7012\tD(x): 0.7973\tD(G(z)): 0.3147 / 0.1742\n",
            "[61/100][200/391]\tLoss_D: 0.8826\tLoss_G: 1.6308\tD(x): 0.7074\tD(G(z)): 0.2404 / 0.1910\n",
            "[61/100][250/391]\tLoss_D: 1.1274\tLoss_G: 1.9503\tD(x): 0.8423\tD(G(z)): 0.5104 / 0.1354\n",
            "[61/100][300/391]\tLoss_D: 0.9677\tLoss_G: 1.6110\tD(x): 0.7525\tD(G(z)): 0.3670 / 0.1938\n",
            "[61/100][350/391]\tLoss_D: 0.9929\tLoss_G: 1.5172\tD(x): 0.7290\tD(G(z)): 0.3687 / 0.2150\n",
            "[62/100][0/391]\tLoss_D: 1.1851\tLoss_G: 0.6554\tD(x): 0.4660\tD(G(z)): 0.1740 / 0.5626\n",
            "[62/100][50/391]\tLoss_D: 0.8894\tLoss_G: 1.4200\tD(x): 0.7222\tD(G(z)): 0.2795 / 0.2359\n",
            "[62/100][100/391]\tLoss_D: 0.9264\tLoss_G: 1.3253\tD(x): 0.7226\tD(G(z)): 0.3076 / 0.2581\n",
            "[62/100][150/391]\tLoss_D: 0.9947\tLoss_G: 1.7148\tD(x): 0.7513\tD(G(z)): 0.3831 / 0.1741\n",
            "[62/100][200/391]\tLoss_D: 0.9260\tLoss_G: 1.6819\tD(x): 0.7357\tD(G(z)): 0.3187 / 0.1785\n",
            "[62/100][250/391]\tLoss_D: 0.8720\tLoss_G: 1.4639\tD(x): 0.7078\tD(G(z)): 0.2444 / 0.2235\n",
            "[62/100][300/391]\tLoss_D: 0.9499\tLoss_G: 1.4576\tD(x): 0.6480\tD(G(z)): 0.2269 / 0.2414\n",
            "[62/100][350/391]\tLoss_D: 1.0669\tLoss_G: 1.6517\tD(x): 0.7181\tD(G(z)): 0.4064 / 0.1961\n",
            "[63/100][0/391]\tLoss_D: 0.8969\tLoss_G: 1.2429\tD(x): 0.6561\tD(G(z)): 0.1936 / 0.2885\n",
            "[63/100][50/391]\tLoss_D: 0.9122\tLoss_G: 1.3919\tD(x): 0.6455\tD(G(z)): 0.1939 / 0.2534\n",
            "[63/100][100/391]\tLoss_D: 1.0116\tLoss_G: 2.0678\tD(x): 0.8591\tD(G(z)): 0.4375 / 0.1185\n",
            "[63/100][150/391]\tLoss_D: 3.3698\tLoss_G: 0.3996\tD(x): 0.0677\tD(G(z)): 0.0317 / 0.8638\n",
            "[63/100][200/391]\tLoss_D: 1.0011\tLoss_G: 1.3134\tD(x): 0.7065\tD(G(z)): 0.3638 / 0.2631\n",
            "[63/100][250/391]\tLoss_D: 0.9336\tLoss_G: 1.7251\tD(x): 0.8194\tD(G(z)): 0.3820 / 0.1708\n",
            "[63/100][300/391]\tLoss_D: 0.9570\tLoss_G: 1.3478\tD(x): 0.6673\tD(G(z)): 0.2734 / 0.2602\n",
            "[63/100][350/391]\tLoss_D: 0.9231\tLoss_G: 1.3429\tD(x): 0.6724\tD(G(z)): 0.2522 / 0.2548\n",
            "[64/100][0/391]\tLoss_D: 1.2395\tLoss_G: 2.2260\tD(x): 0.8861\tD(G(z)): 0.5678 / 0.0995\n",
            "[64/100][50/391]\tLoss_D: 0.9196\tLoss_G: 1.3370\tD(x): 0.6459\tD(G(z)): 0.2026 / 0.2638\n",
            "[64/100][100/391]\tLoss_D: 0.9208\tLoss_G: 1.1817\tD(x): 0.7095\tD(G(z)): 0.2888 / 0.3025\n",
            "[64/100][150/391]\tLoss_D: 0.9292\tLoss_G: 1.6410\tD(x): 0.7578\tD(G(z)): 0.3304 / 0.1886\n",
            "[64/100][200/391]\tLoss_D: 0.9484\tLoss_G: 1.3609\tD(x): 0.6552\tD(G(z)): 0.2461 / 0.2584\n",
            "[64/100][250/391]\tLoss_D: 0.9831\tLoss_G: 1.1292\tD(x): 0.5954\tD(G(z)): 0.2056 / 0.3230\n",
            "[64/100][300/391]\tLoss_D: 1.2913\tLoss_G: 1.9646\tD(x): 0.8325\tD(G(z)): 0.5801 / 0.1388\n",
            "[64/100][350/391]\tLoss_D: 0.9425\tLoss_G: 1.4879\tD(x): 0.6805\tD(G(z)): 0.2853 / 0.2159\n",
            "[65/100][0/391]\tLoss_D: 1.0836\tLoss_G: 1.0102\tD(x): 0.5174\tD(G(z)): 0.1623 / 0.3823\n",
            "[65/100][50/391]\tLoss_D: 1.0203\tLoss_G: 1.0508\tD(x): 0.5705\tD(G(z)): 0.2062 / 0.3598\n",
            "[65/100][100/391]\tLoss_D: 0.8391\tLoss_G: 1.5181\tD(x): 0.7114\tD(G(z)): 0.1838 / 0.2137\n",
            "[65/100][150/391]\tLoss_D: 0.8626\tLoss_G: 1.5097\tD(x): 0.7262\tD(G(z)): 0.2531 / 0.2110\n",
            "[65/100][200/391]\tLoss_D: 1.6216\tLoss_G: 0.7831\tD(x): 0.2917\tD(G(z)): 0.0639 / 0.4956\n",
            "[65/100][250/391]\tLoss_D: 0.9606\tLoss_G: 1.4471\tD(x): 0.7242\tD(G(z)): 0.3434 / 0.2244\n",
            "[65/100][300/391]\tLoss_D: 0.9721\tLoss_G: 2.0154\tD(x): 0.8036\tD(G(z)): 0.3934 / 0.1223\n",
            "[65/100][350/391]\tLoss_D: 0.9334\tLoss_G: 1.2157\tD(x): 0.6759\tD(G(z)): 0.2641 / 0.2973\n",
            "[66/100][0/391]\tLoss_D: 0.7972\tLoss_G: 1.9968\tD(x): 0.7863\tD(G(z)): 0.2211 / 0.1245\n",
            "[66/100][50/391]\tLoss_D: 0.9327\tLoss_G: 1.5515\tD(x): 0.6974\tD(G(z)): 0.2791 / 0.2047\n",
            "[66/100][100/391]\tLoss_D: 0.8716\tLoss_G: 1.4750\tD(x): 0.6821\tD(G(z)): 0.1966 / 0.2259\n",
            "[66/100][150/391]\tLoss_D: 0.8442\tLoss_G: 1.7655\tD(x): 0.7878\tD(G(z)): 0.2702 / 0.1666\n",
            "[66/100][200/391]\tLoss_D: 0.9548\tLoss_G: 1.0830\tD(x): 0.6237\tD(G(z)): 0.2123 / 0.3425\n",
            "[66/100][250/391]\tLoss_D: 0.9149\tLoss_G: 1.4805\tD(x): 0.7697\tD(G(z)): 0.3177 / 0.2290\n",
            "[66/100][300/391]\tLoss_D: 1.3270\tLoss_G: 2.3733\tD(x): 0.8706\tD(G(z)): 0.6074 / 0.0887\n",
            "[66/100][350/391]\tLoss_D: 0.8493\tLoss_G: 1.6225\tD(x): 0.7677\tD(G(z)): 0.2602 / 0.1903\n",
            "[67/100][0/391]\tLoss_D: 1.0002\tLoss_G: 1.4328\tD(x): 0.6609\tD(G(z)): 0.2879 / 0.2439\n",
            "[67/100][50/391]\tLoss_D: 0.9382\tLoss_G: 1.3563\tD(x): 0.6749\tD(G(z)): 0.2614 / 0.2590\n",
            "[67/100][100/391]\tLoss_D: 0.9949\tLoss_G: 1.9782\tD(x): 0.8446\tD(G(z)): 0.4209 / 0.1298\n",
            "[67/100][150/391]\tLoss_D: 0.8440\tLoss_G: 1.4650\tD(x): 0.7677\tD(G(z)): 0.2540 / 0.2272\n",
            "[67/100][200/391]\tLoss_D: 0.9497\tLoss_G: 1.2320\tD(x): 0.6406\tD(G(z)): 0.2278 / 0.2937\n",
            "[67/100][250/391]\tLoss_D: 1.8293\tLoss_G: 0.4343\tD(x): 0.2690\tD(G(z)): 0.2662 / 0.7508\n",
            "[67/100][300/391]\tLoss_D: 1.2019\tLoss_G: 1.1516\tD(x): 0.6044\tD(G(z)): 0.3965 / 0.3244\n",
            "[67/100][350/391]\tLoss_D: 0.9880\tLoss_G: 1.7286\tD(x): 0.7231\tD(G(z)): 0.3539 / 0.1718\n",
            "[68/100][0/391]\tLoss_D: 0.9208\tLoss_G: 1.3118\tD(x): 0.6642\tD(G(z)): 0.2319 / 0.2664\n",
            "[68/100][50/391]\tLoss_D: 0.8419\tLoss_G: 1.6532\tD(x): 0.7490\tD(G(z)): 0.2453 / 0.1854\n",
            "[68/100][100/391]\tLoss_D: 0.8811\tLoss_G: 1.2768\tD(x): 0.6940\tD(G(z)): 0.2325 / 0.2745\n",
            "[68/100][150/391]\tLoss_D: 1.0409\tLoss_G: 1.0666\tD(x): 0.5630\tD(G(z)): 0.2056 / 0.3532\n",
            "[68/100][200/391]\tLoss_D: 0.8997\tLoss_G: 1.6378\tD(x): 0.7367\tD(G(z)): 0.2796 / 0.1906\n",
            "[68/100][250/391]\tLoss_D: 1.0487\tLoss_G: 1.4480\tD(x): 0.7537\tD(G(z)): 0.4216 / 0.2298\n",
            "[68/100][300/391]\tLoss_D: 0.9264\tLoss_G: 1.2316\tD(x): 0.6340\tD(G(z)): 0.1795 / 0.3045\n",
            "[68/100][350/391]\tLoss_D: 0.9132\tLoss_G: 1.5835\tD(x): 0.7206\tD(G(z)): 0.2890 / 0.2008\n",
            "[69/100][0/391]\tLoss_D: 0.9640\tLoss_G: 1.1415\tD(x): 0.6167\tD(G(z)): 0.1981 / 0.3268\n",
            "[69/100][50/391]\tLoss_D: 1.0399\tLoss_G: 0.9802\tD(x): 0.5538\tD(G(z)): 0.1915 / 0.3901\n",
            "[69/100][100/391]\tLoss_D: 0.9520\tLoss_G: 1.1946\tD(x): 0.6382\tD(G(z)): 0.2404 / 0.3032\n",
            "[69/100][150/391]\tLoss_D: 1.0090\tLoss_G: 2.0884\tD(x): 0.8341\tD(G(z)): 0.4316 / 0.1145\n",
            "[69/100][200/391]\tLoss_D: 0.8878\tLoss_G: 1.5644\tD(x): 0.7238\tD(G(z)): 0.2662 / 0.1969\n",
            "[69/100][250/391]\tLoss_D: 0.9846\tLoss_G: 1.2690\tD(x): 0.6062\tD(G(z)): 0.2171 / 0.2866\n",
            "[69/100][300/391]\tLoss_D: 0.9284\tLoss_G: 1.2941\tD(x): 0.6644\tD(G(z)): 0.2335 / 0.2759\n",
            "[69/100][350/391]\tLoss_D: 0.8457\tLoss_G: 1.3991\tD(x): 0.7154\tD(G(z)): 0.2191 / 0.2424\n",
            "[70/100][0/391]\tLoss_D: 1.0560\tLoss_G: 2.0034\tD(x): 0.8274\tD(G(z)): 0.4538 / 0.1252\n",
            "[70/100][50/391]\tLoss_D: 0.9176\tLoss_G: 1.2874\tD(x): 0.6577\tD(G(z)): 0.2247 / 0.2757\n",
            "[70/100][100/391]\tLoss_D: 0.9059\tLoss_G: 1.3714\tD(x): 0.6776\tD(G(z)): 0.2332 / 0.2490\n",
            "[70/100][150/391]\tLoss_D: 0.9601\tLoss_G: 1.3331\tD(x): 0.6360\tD(G(z)): 0.2238 / 0.2702\n",
            "[70/100][200/391]\tLoss_D: 0.9244\tLoss_G: 1.3461\tD(x): 0.6880\tD(G(z)): 0.2683 / 0.2564\n",
            "[70/100][250/391]\tLoss_D: 0.9130\tLoss_G: 1.2020\tD(x): 0.6962\tD(G(z)): 0.2494 / 0.3007\n",
            "[70/100][300/391]\tLoss_D: 0.8998\tLoss_G: 1.9101\tD(x): 0.7924\tD(G(z)): 0.3254 / 0.1419\n",
            "[70/100][350/391]\tLoss_D: 1.0061\tLoss_G: 1.1625\tD(x): 0.5884\tD(G(z)): 0.2023 / 0.3140\n",
            "[71/100][0/391]\tLoss_D: 0.8880\tLoss_G: 1.3309\tD(x): 0.6442\tD(G(z)): 0.1431 / 0.2555\n",
            "[71/100][50/391]\tLoss_D: 0.9263\tLoss_G: 1.2805\tD(x): 0.6810\tD(G(z)): 0.2639 / 0.2793\n",
            "[71/100][100/391]\tLoss_D: 0.8311\tLoss_G: 1.5197\tD(x): 0.6931\tD(G(z)): 0.1457 / 0.2119\n",
            "[71/100][150/391]\tLoss_D: 0.9659\tLoss_G: 2.0635\tD(x): 0.8155\tD(G(z)): 0.3964 / 0.1180\n",
            "[71/100][200/391]\tLoss_D: 0.8286\tLoss_G: 1.6061\tD(x): 0.7686\tD(G(z)): 0.2263 / 0.1975\n",
            "[71/100][250/391]\tLoss_D: 0.8615\tLoss_G: 1.2241\tD(x): 0.6936\tD(G(z)): 0.1961 / 0.2944\n",
            "[71/100][300/391]\tLoss_D: 0.9235\tLoss_G: 1.1308\tD(x): 0.6735\tD(G(z)): 0.2514 / 0.3274\n",
            "[71/100][350/391]\tLoss_D: 1.7170\tLoss_G: 1.0983\tD(x): 0.5939\tD(G(z)): 0.5486 / 0.4126\n",
            "[72/100][0/391]\tLoss_D: 1.3129\tLoss_G: 1.2160\tD(x): 0.6555\tD(G(z)): 0.5260 / 0.2991\n",
            "[72/100][50/391]\tLoss_D: 0.9903\tLoss_G: 1.2600\tD(x): 0.6246\tD(G(z)): 0.2629 / 0.2844\n",
            "[72/100][100/391]\tLoss_D: 0.9649\tLoss_G: 1.3934\tD(x): 0.6224\tD(G(z)): 0.2104 / 0.2512\n",
            "[72/100][150/391]\tLoss_D: 0.9835\tLoss_G: 1.5193\tD(x): 0.8115\tD(G(z)): 0.4015 / 0.2193\n",
            "[72/100][200/391]\tLoss_D: 0.8939\tLoss_G: 1.6337\tD(x): 0.7809\tD(G(z)): 0.3289 / 0.1849\n",
            "[72/100][250/391]\tLoss_D: 0.9345\tLoss_G: 1.5992\tD(x): 0.7243\tD(G(z)): 0.3176 / 0.1939\n",
            "[72/100][300/391]\tLoss_D: 0.8942\tLoss_G: 1.4297\tD(x): 0.7287\tD(G(z)): 0.2840 / 0.2313\n",
            "[72/100][350/391]\tLoss_D: 0.9365\tLoss_G: 1.0699\tD(x): 0.5991\tD(G(z)): 0.1414 / 0.3446\n",
            "[73/100][0/391]\tLoss_D: 0.9297\tLoss_G: 2.1165\tD(x): 0.8146\tD(G(z)): 0.3590 / 0.1168\n",
            "[73/100][50/391]\tLoss_D: 0.9404\tLoss_G: 1.3554\tD(x): 0.6508\tD(G(z)): 0.2456 / 0.2505\n",
            "[73/100][100/391]\tLoss_D: 0.8857\tLoss_G: 1.4946\tD(x): 0.6807\tD(G(z)): 0.2073 / 0.2277\n",
            "[73/100][150/391]\tLoss_D: 0.8439\tLoss_G: 1.6282\tD(x): 0.7691\tD(G(z)): 0.2599 / 0.1937\n",
            "[73/100][200/391]\tLoss_D: 1.2583\tLoss_G: 2.6721\tD(x): 0.8667\tD(G(z)): 0.5652 / 0.0658\n",
            "[73/100][250/391]\tLoss_D: 0.9368\tLoss_G: 1.2421\tD(x): 0.6979\tD(G(z)): 0.2917 / 0.2887\n",
            "[73/100][300/391]\tLoss_D: 0.8192\tLoss_G: 1.6428\tD(x): 0.7475\tD(G(z)): 0.2052 / 0.1933\n",
            "[73/100][350/391]\tLoss_D: 0.9050\tLoss_G: 1.9173\tD(x): 0.7972\tD(G(z)): 0.3547 / 0.1334\n",
            "[74/100][0/391]\tLoss_D: 0.9156\tLoss_G: 1.2232\tD(x): 0.6557\tD(G(z)): 0.2190 / 0.2966\n",
            "[74/100][50/391]\tLoss_D: 0.9308\tLoss_G: 1.4308\tD(x): 0.6187\tD(G(z)): 0.1528 / 0.2422\n",
            "[74/100][100/391]\tLoss_D: 0.8869\tLoss_G: 1.9508\tD(x): 0.8524\tD(G(z)): 0.3505 / 0.1330\n",
            "[74/100][150/391]\tLoss_D: 0.8610\tLoss_G: 1.4821\tD(x): 0.7001\tD(G(z)): 0.2053 / 0.2249\n",
            "[74/100][200/391]\tLoss_D: 1.0403\tLoss_G: 0.9482\tD(x): 0.5787\tD(G(z)): 0.2269 / 0.3955\n",
            "[74/100][250/391]\tLoss_D: 0.9288\tLoss_G: 1.4026\tD(x): 0.6241\tD(G(z)): 0.1785 / 0.2476\n",
            "[74/100][300/391]\tLoss_D: 0.9397\tLoss_G: 1.0951\tD(x): 0.6254\tD(G(z)): 0.2026 / 0.3394\n",
            "[74/100][350/391]\tLoss_D: 0.8951\tLoss_G: 1.1423\tD(x): 0.6653\tD(G(z)): 0.2013 / 0.3181\n",
            "[75/100][0/391]\tLoss_D: 1.0454\tLoss_G: 0.8731\tD(x): 0.5462\tD(G(z)): 0.1605 / 0.4415\n",
            "[75/100][50/391]\tLoss_D: 0.9563\tLoss_G: 1.2008\tD(x): 0.5912\tD(G(z)): 0.1401 / 0.3044\n",
            "[75/100][100/391]\tLoss_D: 0.9420\tLoss_G: 1.2055\tD(x): 0.6847\tD(G(z)): 0.2731 / 0.3124\n",
            "[75/100][150/391]\tLoss_D: 0.8650\tLoss_G: 1.4224\tD(x): 0.7121\tD(G(z)): 0.2198 / 0.2388\n",
            "[75/100][200/391]\tLoss_D: 0.8618\tLoss_G: 1.4907\tD(x): 0.6910\tD(G(z)): 0.1803 / 0.2214\n",
            "[75/100][250/391]\tLoss_D: 0.9270\tLoss_G: 1.4527\tD(x): 0.6564\tD(G(z)): 0.2208 / 0.2376\n",
            "[75/100][300/391]\tLoss_D: 0.9603\tLoss_G: 1.0736\tD(x): 0.5983\tD(G(z)): 0.1580 / 0.3447\n",
            "[75/100][350/391]\tLoss_D: 0.9133\tLoss_G: 1.8011\tD(x): 0.8102\tD(G(z)): 0.3579 / 0.1570\n",
            "[76/100][0/391]\tLoss_D: 0.8735\tLoss_G: 1.6092\tD(x): 0.7873\tD(G(z)): 0.3114 / 0.1917\n",
            "[76/100][50/391]\tLoss_D: 0.8403\tLoss_G: 1.7271\tD(x): 0.7470\tD(G(z)): 0.2286 / 0.1790\n",
            "[76/100][100/391]\tLoss_D: 0.9819\tLoss_G: 2.0677\tD(x): 0.8720\tD(G(z)): 0.4195 / 0.1198\n",
            "[76/100][150/391]\tLoss_D: 1.0605\tLoss_G: 2.2184\tD(x): 0.8314\tD(G(z)): 0.4593 / 0.1039\n",
            "[76/100][200/391]\tLoss_D: 0.8836\tLoss_G: 1.7315\tD(x): 0.8078\tD(G(z)): 0.3261 / 0.1700\n",
            "[76/100][250/391]\tLoss_D: 1.0463\tLoss_G: 0.6068\tD(x): 0.5435\tD(G(z)): 0.1684 / 0.5921\n",
            "[76/100][300/391]\tLoss_D: 0.8459\tLoss_G: 1.5807\tD(x): 0.7286\tD(G(z)): 0.2182 / 0.2124\n",
            "[76/100][350/391]\tLoss_D: 0.9447\tLoss_G: 1.2650\tD(x): 0.6304\tD(G(z)): 0.2090 / 0.2789\n",
            "[77/100][0/391]\tLoss_D: 0.9575\tLoss_G: 1.1488\tD(x): 0.5970\tD(G(z)): 0.1605 / 0.3196\n",
            "[77/100][50/391]\tLoss_D: 0.8931\tLoss_G: 1.4119\tD(x): 0.7423\tD(G(z)): 0.3014 / 0.2346\n",
            "[77/100][100/391]\tLoss_D: 0.8525\tLoss_G: 1.9999\tD(x): 0.8158\tD(G(z)): 0.2977 / 0.1266\n",
            "[77/100][150/391]\tLoss_D: 1.8251\tLoss_G: 3.4891\tD(x): 0.8511\tD(G(z)): 0.7466 / 0.0310\n",
            "[77/100][200/391]\tLoss_D: 0.8787\tLoss_G: 1.8428\tD(x): 0.7496\tD(G(z)): 0.2723 / 0.1568\n",
            "[77/100][250/391]\tLoss_D: 0.9158\tLoss_G: 1.4951\tD(x): 0.7148\tD(G(z)): 0.2832 / 0.2215\n",
            "[77/100][300/391]\tLoss_D: 0.9287\tLoss_G: 1.8506\tD(x): 0.7682\tD(G(z)): 0.3315 / 0.1542\n",
            "[77/100][350/391]\tLoss_D: 0.9567\tLoss_G: 1.5323\tD(x): 0.6820\tD(G(z)): 0.2902 / 0.2157\n",
            "[78/100][0/391]\tLoss_D: 1.1907\tLoss_G: 0.8431\tD(x): 0.4585\tD(G(z)): 0.1707 / 0.4560\n",
            "[78/100][50/391]\tLoss_D: 1.0285\tLoss_G: 2.4414\tD(x): 0.8717\tD(G(z)): 0.4574 / 0.0805\n",
            "[78/100][100/391]\tLoss_D: 0.9240\tLoss_G: 1.1425\tD(x): 0.6397\tD(G(z)): 0.1943 / 0.3208\n",
            "[78/100][150/391]\tLoss_D: 0.9380\tLoss_G: 1.2978\tD(x): 0.6892\tD(G(z)): 0.2677 / 0.2805\n",
            "[78/100][200/391]\tLoss_D: 0.8376\tLoss_G: 1.5037\tD(x): 0.7688\tD(G(z)): 0.2504 / 0.2159\n",
            "[78/100][250/391]\tLoss_D: 0.8436\tLoss_G: 1.7995\tD(x): 0.8480\tD(G(z)): 0.3109 / 0.1575\n",
            "[78/100][300/391]\tLoss_D: 0.9335\tLoss_G: 1.4564\tD(x): 0.6561\tD(G(z)): 0.2439 / 0.2228\n",
            "[78/100][350/391]\tLoss_D: 1.0194\tLoss_G: 1.1305\tD(x): 0.6193\tD(G(z)): 0.2853 / 0.3276\n",
            "[79/100][0/391]\tLoss_D: 0.8688\tLoss_G: 1.5478\tD(x): 0.7433\tD(G(z)): 0.2432 / 0.2174\n",
            "[79/100][50/391]\tLoss_D: 0.8411\tLoss_G: 1.7049\tD(x): 0.7992\tD(G(z)): 0.2812 / 0.1722\n",
            "[79/100][100/391]\tLoss_D: 0.9367\tLoss_G: 2.2878\tD(x): 0.8139\tD(G(z)): 0.3720 / 0.0954\n",
            "[79/100][150/391]\tLoss_D: 0.8609\tLoss_G: 1.5202\tD(x): 0.6810\tD(G(z)): 0.1527 / 0.2191\n",
            "[79/100][200/391]\tLoss_D: 0.9707\tLoss_G: 2.0102\tD(x): 0.8972\tD(G(z)): 0.4209 / 0.1252\n",
            "[79/100][250/391]\tLoss_D: 0.9471\tLoss_G: 1.2091\tD(x): 0.6519\tD(G(z)): 0.2283 / 0.3047\n",
            "[79/100][300/391]\tLoss_D: 0.9614\tLoss_G: 1.5752\tD(x): 0.7126\tD(G(z)): 0.3208 / 0.1984\n",
            "[79/100][350/391]\tLoss_D: 0.8557\tLoss_G: 1.7842\tD(x): 0.7882\tD(G(z)): 0.2895 / 0.1639\n",
            "[80/100][0/391]\tLoss_D: 0.9432\tLoss_G: 2.2293\tD(x): 0.8497\tD(G(z)): 0.3835 / 0.1029\n",
            "[80/100][50/391]\tLoss_D: 1.0616\tLoss_G: 1.4427\tD(x): 0.5388\tD(G(z)): 0.1576 / 0.2389\n",
            "[80/100][100/391]\tLoss_D: 0.8485\tLoss_G: 1.6519\tD(x): 0.7965\tD(G(z)): 0.2878 / 0.1839\n",
            "[80/100][150/391]\tLoss_D: 0.9778\tLoss_G: 1.5887\tD(x): 0.7060\tD(G(z)): 0.3253 / 0.1960\n",
            "[80/100][200/391]\tLoss_D: 0.8908\tLoss_G: 1.3568\tD(x): 0.6451\tD(G(z)): 0.1532 / 0.2587\n",
            "[80/100][250/391]\tLoss_D: 0.8599\tLoss_G: 1.4291\tD(x): 0.7225\tD(G(z)): 0.2272 / 0.2353\n",
            "[80/100][300/391]\tLoss_D: 0.9420\tLoss_G: 1.4400\tD(x): 0.6593\tD(G(z)): 0.2382 / 0.2388\n",
            "[80/100][350/391]\tLoss_D: 0.9106\tLoss_G: 1.4186\tD(x): 0.6626\tD(G(z)): 0.2215 / 0.2374\n",
            "[81/100][0/391]\tLoss_D: 0.8509\tLoss_G: 1.7829\tD(x): 0.7943\tD(G(z)): 0.2931 / 0.1605\n",
            "[81/100][50/391]\tLoss_D: 0.9766\tLoss_G: 1.2097\tD(x): 0.6226\tD(G(z)): 0.2291 / 0.2966\n",
            "[81/100][100/391]\tLoss_D: 0.8854\tLoss_G: 1.8784\tD(x): 0.7924\tD(G(z)): 0.3224 / 0.1466\n",
            "[81/100][150/391]\tLoss_D: 0.9012\tLoss_G: 1.7731\tD(x): 0.8159\tD(G(z)): 0.3287 / 0.1673\n",
            "[81/100][200/391]\tLoss_D: 0.8472\tLoss_G: 1.5118\tD(x): 0.6978\tD(G(z)): 0.1632 / 0.2214\n",
            "[81/100][250/391]\tLoss_D: 1.1083\tLoss_G: 0.8774\tD(x): 0.5128\tD(G(z)): 0.1298 / 0.4492\n",
            "[81/100][300/391]\tLoss_D: 0.8358\tLoss_G: 1.5257\tD(x): 0.7478\tD(G(z)): 0.2258 / 0.2131\n",
            "[81/100][350/391]\tLoss_D: 0.9012\tLoss_G: 1.0921\tD(x): 0.6773\tD(G(z)): 0.2345 / 0.3401\n",
            "[82/100][0/391]\tLoss_D: 0.8987\tLoss_G: 1.8441\tD(x): 0.8521\tD(G(z)): 0.3594 / 0.1486\n",
            "[82/100][50/391]\tLoss_D: 0.8983\tLoss_G: 1.3584\tD(x): 0.6848\tD(G(z)): 0.2233 / 0.2627\n",
            "[82/100][100/391]\tLoss_D: 0.8830\tLoss_G: 2.1514\tD(x): 0.8405\tD(G(z)): 0.3438 / 0.1073\n",
            "[82/100][150/391]\tLoss_D: 0.8195\tLoss_G: 1.6135\tD(x): 0.7331\tD(G(z)): 0.1849 / 0.1923\n",
            "[82/100][200/391]\tLoss_D: 1.0361\tLoss_G: 1.7875\tD(x): 0.8292\tD(G(z)): 0.4169 / 0.1714\n",
            "[82/100][250/391]\tLoss_D: 0.8508\tLoss_G: 2.0979\tD(x): 0.8183\tD(G(z)): 0.3041 / 0.1141\n",
            "[82/100][300/391]\tLoss_D: 0.8736\tLoss_G: 1.4706\tD(x): 0.7044\tD(G(z)): 0.1982 / 0.2305\n",
            "[82/100][350/391]\tLoss_D: 0.8929\tLoss_G: 1.6270\tD(x): 0.7576\tD(G(z)): 0.2974 / 0.1884\n",
            "[83/100][0/391]\tLoss_D: 1.0323\tLoss_G: 1.8467\tD(x): 0.7769\tD(G(z)): 0.4171 / 0.1518\n",
            "[83/100][50/391]\tLoss_D: 0.9538\tLoss_G: 1.1208\tD(x): 0.6482\tD(G(z)): 0.2392 / 0.3383\n",
            "[83/100][100/391]\tLoss_D: 0.8976\tLoss_G: 1.5582\tD(x): 0.7244\tD(G(z)): 0.2782 / 0.2083\n",
            "[83/100][150/391]\tLoss_D: 0.8859\tLoss_G: 1.1485\tD(x): 0.6713\tD(G(z)): 0.1945 / 0.3263\n",
            "[83/100][200/391]\tLoss_D: 0.8975\tLoss_G: 1.1784\tD(x): 0.6668\tD(G(z)): 0.1986 / 0.3184\n",
            "[83/100][250/391]\tLoss_D: 0.8666\tLoss_G: 1.6085\tD(x): 0.7368\tD(G(z)): 0.2496 / 0.1994\n",
            "[83/100][300/391]\tLoss_D: 0.9331\tLoss_G: 2.0070\tD(x): 0.7899\tD(G(z)): 0.3422 / 0.1310\n",
            "[83/100][350/391]\tLoss_D: 0.8729\tLoss_G: 1.6480\tD(x): 0.7363\tD(G(z)): 0.2500 / 0.1931\n",
            "[84/100][0/391]\tLoss_D: 0.9165\tLoss_G: 1.2470\tD(x): 0.6641\tD(G(z)): 0.1968 / 0.2971\n",
            "[84/100][50/391]\tLoss_D: 0.8821\tLoss_G: 1.3715\tD(x): 0.7033\tD(G(z)): 0.2320 / 0.2483\n",
            "[84/100][100/391]\tLoss_D: 0.8802\tLoss_G: 1.3961\tD(x): 0.7091\tD(G(z)): 0.2403 / 0.2471\n",
            "[84/100][150/391]\tLoss_D: 0.8455\tLoss_G: 1.9100\tD(x): 0.7985\tD(G(z)): 0.2888 / 0.1405\n",
            "[84/100][200/391]\tLoss_D: 0.9034\tLoss_G: 1.2728\tD(x): 0.6800\tD(G(z)): 0.2224 / 0.2844\n",
            "[84/100][250/391]\tLoss_D: 0.8447\tLoss_G: 1.5789\tD(x): 0.7877\tD(G(z)): 0.2759 / 0.1951\n",
            "[84/100][300/391]\tLoss_D: 0.9331\tLoss_G: 1.2159\tD(x): 0.6822\tD(G(z)): 0.2564 / 0.2947\n",
            "[84/100][350/391]\tLoss_D: 0.8610\tLoss_G: 1.7197\tD(x): 0.7889\tD(G(z)): 0.2874 / 0.1711\n",
            "[85/100][0/391]\tLoss_D: 0.9122\tLoss_G: 1.3755\tD(x): 0.6888\tD(G(z)): 0.2451 / 0.2539\n",
            "[85/100][50/391]\tLoss_D: 0.8168\tLoss_G: 1.6980\tD(x): 0.7927\tD(G(z)): 0.2626 / 0.1690\n",
            "[85/100][100/391]\tLoss_D: 0.8421\tLoss_G: 1.4495\tD(x): 0.7007\tD(G(z)): 0.1680 / 0.2322\n",
            "[85/100][150/391]\tLoss_D: 0.8961\tLoss_G: 1.1798\tD(x): 0.6897\tD(G(z)): 0.2294 / 0.3077\n",
            "[85/100][200/391]\tLoss_D: 0.8898\tLoss_G: 1.2811\tD(x): 0.6802\tD(G(z)): 0.1930 / 0.2854\n",
            "[85/100][250/391]\tLoss_D: 0.9087\tLoss_G: 1.6201\tD(x): 0.7922\tD(G(z)): 0.3326 / 0.1942\n",
            "[85/100][300/391]\tLoss_D: 0.8421\tLoss_G: 1.8703\tD(x): 0.8005\tD(G(z)): 0.2815 / 0.1467\n",
            "[85/100][350/391]\tLoss_D: 0.8177\tLoss_G: 1.5631\tD(x): 0.7488\tD(G(z)): 0.2195 / 0.1998\n",
            "[86/100][0/391]\tLoss_D: 1.4149\tLoss_G: 0.8297\tD(x): 0.4108\tD(G(z)): 0.2123 / 0.4788\n",
            "[86/100][50/391]\tLoss_D: 0.9241\tLoss_G: 1.2162\tD(x): 0.6778\tD(G(z)): 0.2461 / 0.2948\n",
            "[86/100][100/391]\tLoss_D: 0.9149\tLoss_G: 1.8654\tD(x): 0.7759\tD(G(z)): 0.3232 / 0.1488\n",
            "[86/100][150/391]\tLoss_D: 0.8866\tLoss_G: 1.5067\tD(x): 0.7348\tD(G(z)): 0.2742 / 0.2194\n",
            "[86/100][200/391]\tLoss_D: 0.9649\tLoss_G: 1.9021\tD(x): 0.8421\tD(G(z)): 0.4011 / 0.1422\n",
            "[86/100][250/391]\tLoss_D: 0.8230\tLoss_G: 1.7678\tD(x): 0.8021\tD(G(z)): 0.2627 / 0.1649\n",
            "[86/100][300/391]\tLoss_D: 0.8215\tLoss_G: 1.5294\tD(x): 0.7482\tD(G(z)): 0.1952 / 0.2178\n",
            "[86/100][350/391]\tLoss_D: 1.0548\tLoss_G: 1.6148\tD(x): 0.6858\tD(G(z)): 0.3420 / 0.2010\n",
            "[87/100][0/391]\tLoss_D: 0.7883\tLoss_G: 1.8155\tD(x): 0.7641\tD(G(z)): 0.1700 / 0.1580\n",
            "[87/100][50/391]\tLoss_D: 0.8405\tLoss_G: 1.6857\tD(x): 0.7536\tD(G(z)): 0.2392 / 0.1852\n",
            "[87/100][100/391]\tLoss_D: 0.8421\tLoss_G: 1.3511\tD(x): 0.7283\tD(G(z)): 0.2148 / 0.2593\n",
            "[87/100][150/391]\tLoss_D: 0.8327\tLoss_G: 1.5488\tD(x): 0.7487\tD(G(z)): 0.2261 / 0.2039\n",
            "[87/100][200/391]\tLoss_D: 0.8555\tLoss_G: 1.4643\tD(x): 0.6839\tD(G(z)): 0.1521 / 0.2281\n",
            "[87/100][250/391]\tLoss_D: 0.9245\tLoss_G: 1.4903\tD(x): 0.7319\tD(G(z)): 0.3082 / 0.2239\n",
            "[87/100][300/391]\tLoss_D: 1.4743\tLoss_G: 3.3584\tD(x): 0.8991\tD(G(z)): 0.6450 / 0.0345\n",
            "[87/100][350/391]\tLoss_D: 0.9034\tLoss_G: 1.5568\tD(x): 0.6905\tD(G(z)): 0.2346 / 0.2090\n",
            "[88/100][0/391]\tLoss_D: 0.8958\tLoss_G: 1.2864\tD(x): 0.7079\tD(G(z)): 0.2531 / 0.2809\n",
            "[88/100][50/391]\tLoss_D: 0.8924\tLoss_G: 1.2036\tD(x): 0.6880\tD(G(z)): 0.2249 / 0.3034\n",
            "[88/100][100/391]\tLoss_D: 0.8935\tLoss_G: 1.9132\tD(x): 0.7468\tD(G(z)): 0.2953 / 0.1389\n",
            "[88/100][150/391]\tLoss_D: 0.8259\tLoss_G: 1.7669\tD(x): 0.7507\tD(G(z)): 0.2122 / 0.1690\n",
            "[88/100][200/391]\tLoss_D: 0.9100\tLoss_G: 1.3355\tD(x): 0.6320\tD(G(z)): 0.1515 / 0.2572\n",
            "[88/100][250/391]\tLoss_D: 0.9007\tLoss_G: 2.2385\tD(x): 0.8430\tD(G(z)): 0.3261 / 0.1018\n",
            "[88/100][300/391]\tLoss_D: 0.8556\tLoss_G: 1.6752\tD(x): 0.7282\tD(G(z)): 0.2117 / 0.1861\n",
            "[88/100][350/391]\tLoss_D: 0.8684\tLoss_G: 1.3149\tD(x): 0.6855\tD(G(z)): 0.1698 / 0.2702\n",
            "[89/100][0/391]\tLoss_D: 0.9523\tLoss_G: 2.6627\tD(x): 0.8743\tD(G(z)): 0.4045 / 0.0643\n",
            "[89/100][50/391]\tLoss_D: 0.8469\tLoss_G: 1.4624\tD(x): 0.6938\tD(G(z)): 0.1646 / 0.2301\n",
            "[89/100][100/391]\tLoss_D: 0.8465\tLoss_G: 1.7530\tD(x): 0.7698\tD(G(z)): 0.2607 / 0.1742\n",
            "[89/100][150/391]\tLoss_D: 4.9626\tLoss_G: 2.7218\tD(x): 0.9641\tD(G(z)): 0.9675 / 0.0896\n",
            "[89/100][200/391]\tLoss_D: 0.8651\tLoss_G: 1.6181\tD(x): 0.7340\tD(G(z)): 0.2377 / 0.2058\n",
            "[89/100][250/391]\tLoss_D: 0.8744\tLoss_G: 1.9098\tD(x): 0.8041\tD(G(z)): 0.3145 / 0.1414\n",
            "[89/100][300/391]\tLoss_D: 0.8154\tLoss_G: 1.6389\tD(x): 0.7716\tD(G(z)): 0.2199 / 0.1925\n",
            "[89/100][350/391]\tLoss_D: 0.8986\tLoss_G: 1.5081\tD(x): 0.6910\tD(G(z)): 0.2260 / 0.2157\n",
            "[90/100][0/391]\tLoss_D: 0.8553\tLoss_G: 1.5550\tD(x): 0.7013\tD(G(z)): 0.2042 / 0.2084\n",
            "[90/100][50/391]\tLoss_D: 0.8604\tLoss_G: 1.4403\tD(x): 0.6772\tD(G(z)): 0.1491 / 0.2371\n",
            "[90/100][100/391]\tLoss_D: 0.9319\tLoss_G: 1.3188\tD(x): 0.6224\tD(G(z)): 0.1501 / 0.2717\n",
            "[90/100][150/391]\tLoss_D: 1.4709\tLoss_G: 0.5988\tD(x): 0.3497\tD(G(z)): 0.0781 / 0.5958\n",
            "[90/100][200/391]\tLoss_D: 0.8348\tLoss_G: 1.8210\tD(x): 0.7919\tD(G(z)): 0.2607 / 0.1600\n",
            "[90/100][250/391]\tLoss_D: 0.9358\tLoss_G: 1.0542\tD(x): 0.6388\tD(G(z)): 0.2162 / 0.3537\n",
            "[90/100][300/391]\tLoss_D: 0.8680\tLoss_G: 1.2753\tD(x): 0.7023\tD(G(z)): 0.2077 / 0.2789\n",
            "[90/100][350/391]\tLoss_D: 0.8325\tLoss_G: 1.8474\tD(x): 0.7891\tD(G(z)): 0.2529 / 0.1563\n",
            "[91/100][0/391]\tLoss_D: 0.9309\tLoss_G: 1.1004\tD(x): 0.6663\tD(G(z)): 0.2389 / 0.3365\n",
            "[91/100][50/391]\tLoss_D: 0.8476\tLoss_G: 1.6939\tD(x): 0.7954\tD(G(z)): 0.2838 / 0.1795\n",
            "[91/100][100/391]\tLoss_D: 0.8603\tLoss_G: 1.4058\tD(x): 0.7318\tD(G(z)): 0.2427 / 0.2418\n",
            "[91/100][150/391]\tLoss_D: 0.9008\tLoss_G: 1.3615\tD(x): 0.6849\tD(G(z)): 0.2245 / 0.2575\n",
            "[91/100][200/391]\tLoss_D: 0.8640\tLoss_G: 2.1443\tD(x): 0.8422\tD(G(z)): 0.3136 / 0.1125\n",
            "[91/100][250/391]\tLoss_D: 0.8714\tLoss_G: 1.4776\tD(x): 0.7177\tD(G(z)): 0.2412 / 0.2235\n",
            "[91/100][300/391]\tLoss_D: 1.1834\tLoss_G: 2.3906\tD(x): 0.8945\tD(G(z)): 0.5251 / 0.0928\n",
            "[91/100][350/391]\tLoss_D: 0.8926\tLoss_G: 1.3657\tD(x): 0.6460\tD(G(z)): 0.1486 / 0.2544\n",
            "[92/100][0/391]\tLoss_D: 1.1757\tLoss_G: 0.9843\tD(x): 0.4753\tD(G(z)): 0.1410 / 0.4019\n",
            "[92/100][50/391]\tLoss_D: 0.9742\tLoss_G: 1.7669\tD(x): 0.7585\tD(G(z)): 0.3601 / 0.1660\n",
            "[92/100][100/391]\tLoss_D: 0.9324\tLoss_G: 1.1996\tD(x): 0.6272\tD(G(z)): 0.1752 / 0.3094\n",
            "[92/100][150/391]\tLoss_D: 0.9020\tLoss_G: 1.7427\tD(x): 0.7638\tD(G(z)): 0.3140 / 0.1691\n",
            "[92/100][200/391]\tLoss_D: 0.8115\tLoss_G: 1.6665\tD(x): 0.7836\tD(G(z)): 0.2250 / 0.1876\n",
            "[92/100][250/391]\tLoss_D: 0.8308\tLoss_G: 1.8975\tD(x): 0.8048\tD(G(z)): 0.2804 / 0.1405\n",
            "[92/100][300/391]\tLoss_D: 0.8959\tLoss_G: 1.9235\tD(x): 0.8079\tD(G(z)): 0.3283 / 0.1387\n",
            "[92/100][350/391]\tLoss_D: 0.8412\tLoss_G: 1.9374\tD(x): 0.8412\tD(G(z)): 0.2825 / 0.1417\n",
            "[93/100][0/391]\tLoss_D: 0.8197\tLoss_G: 1.7087\tD(x): 0.7665\tD(G(z)): 0.2204 / 0.1782\n",
            "[93/100][50/391]\tLoss_D: 0.7862\tLoss_G: 1.8481\tD(x): 0.8110\tD(G(z)): 0.2228 / 0.1535\n",
            "[93/100][100/391]\tLoss_D: 0.8634\tLoss_G: 1.3538\tD(x): 0.6685\tD(G(z)): 0.1221 / 0.2659\n",
            "[93/100][150/391]\tLoss_D: 0.8023\tLoss_G: 1.8419\tD(x): 0.7725\tD(G(z)): 0.2060 / 0.1545\n",
            "[93/100][200/391]\tLoss_D: 0.9211\tLoss_G: 2.1319\tD(x): 0.7969\tD(G(z)): 0.3374 / 0.1140\n",
            "[93/100][250/391]\tLoss_D: 0.9225\tLoss_G: 1.3691\tD(x): 0.6345\tD(G(z)): 0.1723 / 0.2546\n",
            "[93/100][300/391]\tLoss_D: 0.9958\tLoss_G: 0.9345\tD(x): 0.6095\tD(G(z)): 0.2008 / 0.4067\n",
            "[93/100][350/391]\tLoss_D: 0.9618\tLoss_G: 1.2573\tD(x): 0.6393\tD(G(z)): 0.2260 / 0.2810\n",
            "[94/100][0/391]\tLoss_D: 0.8568\tLoss_G: 1.7093\tD(x): 0.7522\tD(G(z)): 0.2536 / 0.1723\n",
            "[94/100][50/391]\tLoss_D: 0.9651\tLoss_G: 2.2890\tD(x): 0.9042\tD(G(z)): 0.4030 / 0.0985\n",
            "[94/100][100/391]\tLoss_D: 0.9506\tLoss_G: 1.8629\tD(x): 0.8267\tD(G(z)): 0.3845 / 0.1468\n",
            "[94/100][150/391]\tLoss_D: 0.8876\tLoss_G: 2.4676\tD(x): 0.8410\tD(G(z)): 0.3320 / 0.0795\n",
            "[94/100][200/391]\tLoss_D: 0.8782\tLoss_G: 2.0973\tD(x): 0.8710\tD(G(z)): 0.3291 / 0.1226\n",
            "[94/100][250/391]\tLoss_D: 0.8126\tLoss_G: 1.7321\tD(x): 0.8123\tD(G(z)): 0.2478 / 0.1754\n",
            "[94/100][300/391]\tLoss_D: 0.8551\tLoss_G: 2.2520\tD(x): 0.8330\tD(G(z)): 0.2922 / 0.1002\n",
            "[94/100][350/391]\tLoss_D: 0.7958\tLoss_G: 1.9686\tD(x): 0.7856\tD(G(z)): 0.2100 / 0.1360\n",
            "[95/100][0/391]\tLoss_D: 1.7371\tLoss_G: 0.7437\tD(x): 0.2974\tD(G(z)): 0.2360 / 0.5193\n",
            "[95/100][50/391]\tLoss_D: 0.8742\tLoss_G: 1.4713\tD(x): 0.7195\tD(G(z)): 0.2447 / 0.2260\n",
            "[95/100][100/391]\tLoss_D: 0.9698\tLoss_G: 2.1067\tD(x): 0.8741\tD(G(z)): 0.4034 / 0.1195\n",
            "[95/100][150/391]\tLoss_D: 0.7820\tLoss_G: 1.6363\tD(x): 0.7884\tD(G(z)): 0.2087 / 0.1894\n",
            "[95/100][200/391]\tLoss_D: 0.8540\tLoss_G: 1.6888\tD(x): 0.7369\tD(G(z)): 0.2151 / 0.1939\n",
            "[95/100][250/391]\tLoss_D: 0.8666\tLoss_G: 1.2734\tD(x): 0.6741\tD(G(z)): 0.1555 / 0.2906\n",
            "[95/100][300/391]\tLoss_D: 0.8479\tLoss_G: 1.7288\tD(x): 0.7506\tD(G(z)): 0.2309 / 0.1746\n",
            "[95/100][350/391]\tLoss_D: 0.8469\tLoss_G: 1.4109\tD(x): 0.7243\tD(G(z)): 0.2109 / 0.2476\n",
            "[96/100][0/391]\tLoss_D: 0.8583\tLoss_G: 1.8833\tD(x): 0.8259\tD(G(z)): 0.2936 / 0.1457\n",
            "[96/100][50/391]\tLoss_D: 0.9279\tLoss_G: 1.2044\tD(x): 0.6296\tD(G(z)): 0.1493 / 0.3093\n",
            "[96/100][100/391]\tLoss_D: 0.8598\tLoss_G: 1.2994\tD(x): 0.7142\tD(G(z)): 0.2180 / 0.2777\n",
            "[96/100][150/391]\tLoss_D: 0.8267\tLoss_G: 1.7131\tD(x): 0.7628\tD(G(z)): 0.2211 / 0.1750\n",
            "[96/100][200/391]\tLoss_D: 2.0186\tLoss_G: 0.3880\tD(x): 0.2051\tD(G(z)): 0.0616 / 0.8299\n",
            "[96/100][250/391]\tLoss_D: 0.9161\tLoss_G: 1.6594\tD(x): 0.7219\tD(G(z)): 0.2848 / 0.1872\n",
            "[96/100][300/391]\tLoss_D: 1.0280\tLoss_G: 1.4215\tD(x): 0.5842\tD(G(z)): 0.2054 / 0.2579\n",
            "[96/100][350/391]\tLoss_D: 0.8609\tLoss_G: 1.8817\tD(x): 0.8392\tD(G(z)): 0.3083 / 0.1462\n",
            "[97/100][0/391]\tLoss_D: 0.8214\tLoss_G: 1.5850\tD(x): 0.7530\tD(G(z)): 0.2067 / 0.2057\n",
            "[97/100][50/391]\tLoss_D: 0.8152\tLoss_G: 1.6887\tD(x): 0.7835\tD(G(z)): 0.2287 / 0.1834\n",
            "[97/100][100/391]\tLoss_D: 0.8298\tLoss_G: 1.8364\tD(x): 0.8372\tD(G(z)): 0.2883 / 0.1551\n",
            "[97/100][150/391]\tLoss_D: 0.8633\tLoss_G: 1.4810\tD(x): 0.6692\tD(G(z)): 0.1332 / 0.2373\n",
            "[97/100][200/391]\tLoss_D: 1.2873\tLoss_G: 0.8234\tD(x): 0.4128\tD(G(z)): 0.1041 / 0.4647\n",
            "[97/100][250/391]\tLoss_D: 0.9195\tLoss_G: 1.6826\tD(x): 0.7206\tD(G(z)): 0.2852 / 0.1795\n",
            "[97/100][300/391]\tLoss_D: 0.8131\tLoss_G: 1.5168\tD(x): 0.7339\tD(G(z)): 0.1942 / 0.2108\n",
            "[97/100][350/391]\tLoss_D: 0.8343\tLoss_G: 1.8352\tD(x): 0.7508\tD(G(z)): 0.2182 / 0.1554\n",
            "[98/100][0/391]\tLoss_D: 0.9783\tLoss_G: 1.6332\tD(x): 0.7454\tD(G(z)): 0.3592 / 0.1915\n",
            "[98/100][50/391]\tLoss_D: 0.7958\tLoss_G: 1.7285\tD(x): 0.8047\tD(G(z)): 0.2274 / 0.1704\n",
            "[98/100][100/391]\tLoss_D: 1.4670\tLoss_G: 1.1687\tD(x): 0.6304\tD(G(z)): 0.5687 / 0.3497\n",
            "[98/100][150/391]\tLoss_D: 0.9380\tLoss_G: 1.6674\tD(x): 0.7400\tD(G(z)): 0.3099 / 0.1884\n",
            "[98/100][200/391]\tLoss_D: 0.9422\tLoss_G: 1.5412\tD(x): 0.6591\tD(G(z)): 0.2449 / 0.2077\n",
            "[98/100][250/391]\tLoss_D: 0.8945\tLoss_G: 1.3527\tD(x): 0.7139\tD(G(z)): 0.2542 / 0.2566\n",
            "[98/100][300/391]\tLoss_D: 0.9271\tLoss_G: 1.9010\tD(x): 0.8007\tD(G(z)): 0.3550 / 0.1435\n",
            "[98/100][350/391]\tLoss_D: 0.8846\tLoss_G: 1.5432\tD(x): 0.6823\tD(G(z)): 0.1974 / 0.2200\n",
            "[99/100][0/391]\tLoss_D: 0.8561\tLoss_G: 1.6183\tD(x): 0.7261\tD(G(z)): 0.2201 / 0.1948\n",
            "[99/100][50/391]\tLoss_D: 0.7919\tLoss_G: 1.7422\tD(x): 0.7624\tD(G(z)): 0.1852 / 0.1674\n",
            "[99/100][100/391]\tLoss_D: 0.8206\tLoss_G: 2.0683\tD(x): 0.7883\tD(G(z)): 0.2495 / 0.1231\n",
            "[99/100][150/391]\tLoss_D: 0.8074\tLoss_G: 1.7575\tD(x): 0.8246\tD(G(z)): 0.2602 / 0.1683\n",
            "[99/100][200/391]\tLoss_D: 0.8506\tLoss_G: 1.6087\tD(x): 0.7264\tD(G(z)): 0.2078 / 0.1961\n",
            "[99/100][250/391]\tLoss_D: 0.9211\tLoss_G: 0.8848\tD(x): 0.6834\tD(G(z)): 0.2469 / 0.4283\n",
            "[99/100][300/391]\tLoss_D: 0.9233\tLoss_G: 1.4192\tD(x): 0.6464\tD(G(z)): 0.1880 / 0.2472\n",
            "[99/100][350/391]\tLoss_D: 0.8768\tLoss_G: 1.8337\tD(x): 0.7438\tD(G(z)): 0.2657 / 0.1571\n",
            "[100/100][0/391]\tLoss_D: 0.8802\tLoss_G: 1.5307\tD(x): 0.7031\tD(G(z)): 0.2187 / 0.2111\n",
            "[100/100][50/391]\tLoss_D: 0.8071\tLoss_G: 1.8734\tD(x): 0.8061\tD(G(z)): 0.2437 / 0.1522\n",
            "[100/100][100/391]\tLoss_D: 0.8254\tLoss_G: 1.7763\tD(x): 0.8180\tD(G(z)): 0.2746 / 0.1633\n",
            "[100/100][150/391]\tLoss_D: 0.7883\tLoss_G: 1.5936\tD(x): 0.7423\tD(G(z)): 0.1328 / 0.2021\n",
            "[100/100][200/391]\tLoss_D: 1.8406\tLoss_G: 0.5690\tD(x): 0.2992\tD(G(z)): 0.2319 / 0.6652\n",
            "[100/100][250/391]\tLoss_D: 0.9424\tLoss_G: 1.6334\tD(x): 0.7714\tD(G(z)): 0.3440 / 0.1956\n",
            "[100/100][300/391]\tLoss_D: 0.8729\tLoss_G: 1.4284\tD(x): 0.7394\tD(G(z)): 0.2505 / 0.2409\n",
            "[100/100][350/391]\tLoss_D: 0.8682\tLoss_G: 1.4281\tD(x): 0.6825\tD(G(z)): 0.1908 / 0.2311\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGiD4A051QWH"
      },
      "source": [
        "## Original CIFAR10의 Inception Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qoIjDUf38Sz",
        "outputId": "facf64e2-e1d3-4b93-a67f-56a098f1f610"
      },
      "source": [
        "!git clone https://github.com/sbarratt/inception-score-pytorch.git"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'inception-score-pytorch'...\n",
            "remote: Enumerating objects: 43, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 43 (delta 0), reused 1 (delta 0), pack-reused 40\u001b[K\n",
            "Unpacking objects: 100% (43/43), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192,
          "referenced_widgets": [
            "a685ada720b644b280841f0590376e52",
            "ae1abdf3fffe46e8ae92b9229695e41a",
            "bd14da4840cc4dc39428abd0761dd1d4",
            "641368523a33461a9d04c916c7d5136a",
            "90755ae77e87447999b2d90ea3adcafe",
            "7ccad5a8f8bc49f5b116ad82467e89b2",
            "d81e495c3900474b86cffbdac341912d",
            "0335acc1438948589dee555dfaf66820"
          ]
        },
        "id": "XXNVB1Lm3iYT",
        "outputId": "a316d1ad-ee7a-436d-8920-1913f3639915"
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/inception-score-pytorch')\n",
        "from inception_score import inception_score\n",
        "\n",
        "x = np.rollaxis(trainset.data, 3, 1)  \n",
        "\n",
        "class IgnoreLabelDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, orig):\n",
        "        self.orig = orig\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.orig[index][0]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.orig)\n",
        "\n",
        "print(inception_score(IgnoreLabelDataset(trainset), cuda=True, batch_size=32, resize=True, splits=10))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth\" to /root/.cache/torch/hub/checkpoints/inception_v3_google-1a9a5a14.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a685ada720b644b280841f0590376e52",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=108857766.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3458: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode)\n",
            "/content/inception-score-pytorch/inception_score.py:44: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.softmax(x).data.cpu().numpy()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(9.672782457317373, 0.14991608790468258)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ed4NvlH_CFeA",
        "outputId": "1756412c-275b-474b-c033-fef07726cbea"
      },
      "source": [
        "id = IgnoreLabelDataset(trainset)\n",
        "id[100].shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 32, 32])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ig0vtfTYRfPv"
      },
      "source": [
        "## 생성한 image의 inception score 측정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPC0MAIjQElY",
        "outputId": "088df77f-682b-4cc1-cae0-0850992df901"
      },
      "source": [
        "\n",
        "eval_images = []\n",
        "for i in range(1000):\n",
        "    gen_noise = torch.randn(64, config.nz, 1, 1, device=device)\n",
        "    with torch.no_grad():\n",
        "        fake = gen(gen_noise).detach().cpu()\n",
        "    eval_images += fake\n",
        "\n",
        "print(len(eval_images))\n",
        "print(eval_images[0].shape)\n",
        "print(inception_score(eval_images, cuda=True, batch_size=32, resize=True, splits=10))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "64000\n",
            "torch.Size([3, 32, 32])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3458: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode)\n",
            "/content/inception-score-pytorch/inception_score.py:44: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.softmax(x).data.cpu().numpy()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(5.14063443046805, 0.06881516756046895)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}